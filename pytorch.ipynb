{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6q4DL8Z4JP9K",
        "jIuwscxYG3kA",
        "nnLG-dwwMe6w",
        "heXpDimsanKL",
        "ia4HyJ5zUYJC",
        "HlLgKe9_To_a",
        "FZJ_UZfdm2yq",
        "OcobxzOsgmMe",
        "M2IOumsgcqSk",
        "1NI78k428mml",
        "WhNvJaLMwqzB"
      ],
      "authorship_tag": "ABX9TyM9PKr03GcR4nGyB7gDn5pD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beamscource/colab_notebooks/blob/main/pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary based on Programming PyTorch, NLP with PyTorch and https://deeplearning.cs.cmu.edu/F22/index.html."
      ],
      "metadata": {
        "id": "EugY5JiWDFQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional resources at https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.html"
      ],
      "metadata": {
        "id": "D-avl5OESxGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "v5HyjCAhV6jT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch is a Python library which offers an **eager approach to differentiation** instead of defining static graphs, allowing for greater flexibility in the way networks are created, trained, and operated.\n",
        "\n",
        "Similar to DyNet and Chainer, and in contrast to static frameworks like TensorFlow/Theano/Caffe, models are not compiled before execution. \n",
        "\n",
        "PyTorch has two lineages. First, it derives many features and concepts from Torch, which was a Lua-based neural network library that dates back to 2002. Its other major parent is Chainer, created in Japan in 2015.\n",
        "\n",
        "The library also comes with modules that help with manipulating text, images, and audio (*torchtext*, *torchvision*, and *torchaudio*), along with built-in variants of popular architectures such as ResNet (with weights that can be downloaded to provide assistance with *transfer learning*).\n",
        "\n",
        "In 2022, about 85% of pre-trained models on HuggingFace are PyTorch models (https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2022/). Despite the fact that PyTorch is used by companies like Twitter, Salesforce, Tesla, Uber, and NVIDIA, the consensus seems to be that TF still offers better native deployment capabilities and that tf.keras might be better suited for a complete beginner."
      ],
      "metadata": {
        "id": "a-8pyuqhWl-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All code examples can be found at https://github.com/falloutdurham/beginners-pytorch-deep-learning For more infos and tutorials see https://pytorch.org/hub/"
      ],
      "metadata": {
        "id": "a2MaJ7GgWLft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "GnsgtHqiHBPq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cNwx3pipHEtq",
        "outputId": "ebceaeea-5e49-4abe-a183-3af5c82faacc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.12.1+cu113'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors"
      ],
      "metadata": {
        "id": "iS_MyDcDREj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basics"
      ],
      "metadata": {
        "id": "6q4DL8Z4JP9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors are objects (\"multidimensional arrays\" or matrices) which hold numerical data of a single type used to propagate through the network. For example, a 1st-order tensor is a vector (one dimensional array) and 2nd-order tensor is a matrix. If you are coming from Matlab or NUmPy, this feels very familiar."
      ],
      "metadata": {
        "id": "wdU3bd-99zfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a tensor from Python lists\n",
        "x = torch.tensor([[0,0,1],[1,1,1],[0,0,0]])\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li2WqHJND70Q",
        "outputId": "ecf6f4c1-8c25-47f1-9ed0-6d0a042fd99c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 1],\n",
              "        [1, 1, 1],\n",
              "        [0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.type()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-UpzAArLEMjh",
        "outputId": "793da8c6-893b-4082-e241-2005c4e6e104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.LongTensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# investigating the size of a tensor\n",
        "x.shape"
      ],
      "metadata": {
        "id": "8DZEpme-EMyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf52f46-7e2c-4a99-ef6e-a06b9638010f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# or\n",
        "x.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkdDfCqkLY76",
        "outputId": "0de23fa6-6bba-40c8-bac6-a61f15de742a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYmwWhUbRYP6"
      },
      "source": [
        "# helper function to investigate a tensor\n",
        "def describe(x):\n",
        "  print(f\"Type: {x.type()}\")\n",
        "  print(f\"Shape/size: {x.shape}\")\n",
        "  print(f\"Values: \\n{x}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO-u9AEyR6KC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf3252d-27e1-4759-e4a8-823ba89c79d5"
      },
      "source": [
        "describe(torch.Tensor(2, 3))\n",
        "describe(torch.rand(2, 3))   # uniform randomdescribe\n",
        "describe(torch.randn(2, 3))  # random normal"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1.9839e-35, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0.3545, 0.2646, 0.6202],\n",
            "        [0.7330, 0.5283, 0.9949]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 1.2141,  1.3971, -0.0657],\n",
            "        [-0.0966, -0.0245,  0.8139]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# special tensors\n",
        "describe(torch.eye(3))\n",
        "describe(torch.ones(2,3))\n",
        "describe(torch.zeros(2,3))\n",
        "describe(torch.arange(0,3))"
      ],
      "metadata": {
        "id": "gfoX9AbSFkEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c56910b2-85ea-43e2-9ab6-8508558ef650"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3])\n",
            "Values: \n",
            "tensor([0, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a tensor from NumPy array\n",
        "# the type of the created tensor is DoubleTensor which corresponds to NumPy\n",
        "# float64 matrix\n",
        "npy  =  np.random.rand(2,  3)\n",
        "describe(torch.from_numpy(npy))\n",
        "# or\n",
        "describe(torch.as_tensor(npy))\n",
        "npy"
      ],
      "metadata": {
        "id": "XZ8Vl4ozSI0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# export to numpy array\n",
        "x_np = x.numpy()\n",
        "print(x_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rneq8s6SItMd",
        "outputId": "ebf7bd5e-db6f-4698-ec00-e9cc525cdac2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.tensor() always copies data. If you have a numpy array and want to avoid a copy, use torch.as_tensor()."
      ],
      "metadata": {
        "id": "2FTnuyj9L29m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create uninitialized tensor\n",
        "x = torch.FloatTensor(2,3)\n",
        "print(x)\n",
        "# initialize/set to zeros\n",
        "x.zero_()\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z3w_rGnJq73",
        "outputId": "49d8f5ce-4bc6-4f83-8c8a-5d14f2350967"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.9839e-35, 0.0000e+00, 1.4013e-45],\n",
            "        [0.0000e+00, 2.8026e-45, 0.0000e+00]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create random tensor (seed for repeatability)\n",
        "torch.manual_seed(123)\n",
        "x=torch.randn(2,3)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "sS5TZpibKAuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Different types"
      ],
      "metadata": {
        "id": "jIuwscxYG3kA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The default  tensor  type  when  using  torch.Tensor  constructor  is  a torch.FloatTensor. But it's possible to convert it to float,  long,  double format  by  specifying  it  at the initialization  or  using  one  of  the typecasting  methods. The most common types you will use are `IntTensor` and `FloatTensor`.\n",
        "\n",
        "See more infos at https://pytorch.org/docs/stable/tensors.html"
      ],
      "metadata": {
        "id": "0GzDJ94-NvOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using dtype at initialization\n",
        "torch.zeros([2, 4], dtype=torch.int32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghbEhd3QILqr",
        "outputId": "3c3a6766-fbb9-49ba-9263-9754290bd451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0],\n",
              "        [0, 0, 0, 0]], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calling a specific constructor at initialization\n",
        "x = torch.FloatTensor([[1, 2, 3],\n",
        "                   [4,5,6]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9IulhcRKED0",
        "outputId": "24a5ad91-eb56-4986-83f4-9e19a4ab3da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# typecasting\n",
        "x.long()"
      ],
      "metadata": {
        "id": "huSO6702K8O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indexing and slicing"
      ],
      "metadata": {
        "id": "nnLG-dwwMe6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a tensor with a short-cut\n",
        "x = torch.arange(6).view(2, 3)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuHqSI-SM7H2",
        "outputId": "9a1e75a0-7667-4a83-c2a5-24877c0dbe5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2],\n",
              "        [3, 4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# indexing into a tensor works like in hierarchical lists (standard Python)\n",
        "x[0][1:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUxGfoVtFOu9",
        "outputId": "e3374ec2-dc94-4a79-8831-add569a38bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# but also like in NumPy\n",
        "x[0,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ec7JX0eNzzV",
        "outputId": "b5c49913-6684-41c0-8cce-ca35e5a37972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# access the first two elements in the first row (indexing is starting at zero)\n",
        "# take from the row at index zero all elements until the element at index 2\n",
        "x[0, :2] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtjQDmxVOxEc",
        "outputId": "2b8fbdde-a0ae-4cbd-fda0-9736f782dcba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[1,1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DKMd9UaPPew",
        "outputId": "d874dd0e-2bf9-4e3f-b9d9-4fe1349b2828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# access scalar values from a single-element tensor\n",
        "torch.rand(1).item()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15Sbnb1OGSry",
        "outputId": "5a9b861a-f7c3-4986-f96c-25172fe868a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5620666146278381"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# replace all elements of a tensor\n",
        "x = torch.ones(4,8)\n",
        "x.fill_(5)\n",
        "x"
      ],
      "metadata": {
        "id": "A0-xiwgpEb9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any PyTorch method with an underscore (_) refers to an inplace operation; that is, it modifies the content in place without creating a new object."
      ],
      "metadata": {
        "id": "HXLYLnOJJMYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# indexing using PyTorch functions\n",
        "# indices have to be of the type LongTensor\n",
        "print(x)\n",
        "indices = torch.LongTensor([0, 0])\n",
        "# joining first row into a new tensor\n",
        "describe(torch.index_select(x, dim=0, index=indices))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8GoGcEkYEhh",
        "outputId": "608ab873-8482-4656-e9bc-785957381b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4068e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00,        nan, 4.7399e+16],\n",
            "        [4.4721e+21, 1.5956e+25, 4.7399e+16, 2.3868e-06, 1.4838e-41, 0.0000e+00]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 6])\n",
            "Values: \n",
            "tensor([[1.4068e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00,        nan, 4.7399e+16],\n",
            "        [1.4068e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00,        nan, 4.7399e+16]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting non-contogous elements by passing tensors as indices\n",
        "print(x)\n",
        "row_indices = torch.arange(2).long() # take from rows zero and one\n",
        "col_indices = torch.LongTensor([0, 1]) # take from colums zero and one\n",
        "print(row_indices)\n",
        "print(col_indices)\n",
        "describe(x[row_indices, col_indices])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI3aLn0TZIWF",
        "outputId": "18baccf5-37c1-4ba1-f2dc-6834b3b08642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4068e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00,        nan, 4.7399e+16],\n",
            "        [4.4721e+21, 1.5956e+25, 4.7399e+16, 2.3868e-06, 1.4838e-41, 0.0000e+00]])\n",
            "tensor([0, 1])\n",
            "tensor([0, 1])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2])\n",
            "Values: \n",
            "tensor([1.4068e-34, 1.5956e+25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Concatenating"
      ],
      "metadata": {
        "id": "heXpDimsanKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# on columns\n",
        "print(x)\n",
        "describe(torch.cat([x, x], dim=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGWGBaYvau5j",
        "outputId": "67adf324-b0cc-47c5-ec8c-4669fd0c0886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4068e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00,        nan, 4.7399e+16],\n",
            "        [4.4721e+21, 1.5956e+25, 4.7399e+16, 2.3868e-06, 1.4838e-41, 0.0000e+00]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([4, 6])\n",
            "Values: \n",
            "tensor([[1.4068e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00,        nan, 4.7399e+16],\n",
            "        [4.4721e+21, 1.5956e+25, 4.7399e+16, 2.3868e-06, 1.4838e-41, 0.0000e+00],\n",
            "        [1.4068e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00,        nan, 4.7399e+16],\n",
            "        [4.4721e+21, 1.5956e+25, 4.7399e+16, 2.3868e-06, 1.4838e-41, 0.0000e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on rows\n",
        "print(y)\n",
        "describe(torch.cat([y, y], dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVghejRUbBFk",
        "outputId": "497e9fb2-2c44-4b59-f47c-dd59dcef03bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4068e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00],\n",
            "        [       nan, 4.7399e+16, 4.4721e+21, 1.5956e+25],\n",
            "        [4.7399e+16, 2.3868e-06, 1.4838e-41, 0.0000e+00]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 8])\n",
            "Values: \n",
            "tensor([[1.4068e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00, 1.4068e-34, 0.0000e+00,\n",
            "         3.3631e-44, 0.0000e+00],\n",
            "        [       nan, 4.7399e+16, 4.4721e+21, 1.5956e+25,        nan, 4.7399e+16,\n",
            "         4.4721e+21, 1.5956e+25],\n",
            "        [4.7399e+16, 2.3868e-06, 1.4838e-41, 0.0000e+00, 4.7399e+16, 2.3868e-06,\n",
            "         1.4838e-41, 0.0000e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to keep tensors as separated elements\n",
        "print(y)\n",
        "describe(torch.stack([y, y], dim=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-pOTutKbUDa",
        "outputId": "05083fdd-7312-40fe-cfa3-9ef10ae7228f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4068e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00],\n",
            "        [       nan, 4.7399e+16, 4.4721e+21, 1.5956e+25],\n",
            "        [4.7399e+16, 2.3868e-06, 1.4838e-41, 0.0000e+00]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3, 4])\n",
            "Values: \n",
            "tensor([[[1.4068e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00],\n",
            "         [       nan, 4.7399e+16, 4.4721e+21, 1.5956e+25],\n",
            "         [4.7399e+16, 2.3868e-06, 1.4838e-41, 0.0000e+00]],\n",
            "\n",
            "        [[1.4068e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00],\n",
            "         [       nan, 4.7399e+16, 4.4721e+21, 1.5956e+25],\n",
            "         [4.7399e+16, 2.3868e-06, 1.4838e-41, 0.0000e+00]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)\n",
        "describe(torch.stack([y, y], dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GSuDfcab1Q8",
        "outputId": "9575e133-bb23-4497-aa66-dcb6cee1960d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4068e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00],\n",
            "        [       nan, 4.7399e+16, 4.4721e+21, 1.5956e+25],\n",
            "        [4.7399e+16, 2.3868e-06, 1.4838e-41, 0.0000e+00]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 2, 4])\n",
            "Values: \n",
            "tensor([[[1.4068e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00],\n",
            "         [1.4068e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00]],\n",
            "\n",
            "        [[       nan, 4.7399e+16, 4.4721e+21, 1.5956e+25],\n",
            "         [       nan, 4.7399e+16, 4.4721e+21, 1.5956e+25]],\n",
            "\n",
            "        [[4.7399e+16, 2.3868e-06, 1.4838e-41, 0.0000e+00],\n",
            "         [4.7399e+16, 2.3868e-06, 1.4838e-41, 0.0000e+00]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manipulating tensors' dimensions"
      ],
      "metadata": {
        "id": "ia4HyJ5zUYJC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X44T7ZrxicpS",
        "outputId": "78290576-aaea-4a3f-da96-96b80b910886"
      },
      "source": [
        "# change dimensions of the tensor\n",
        "x = torch.Tensor(2,6)\n",
        "print(x)\n",
        "# view is not changing the original tensor\n",
        "# you have to assign it to a new tensor\n",
        "x.view(3, 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4062e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00,        nan, 1.5975e-43],\n",
            "        [4.4721e+21, 1.5956e+25, 4.7399e+16, 2.3868e-06, 1.4838e-41, 1.5695e-43]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.4062e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00],\n",
              "        [       nan, 1.5975e-43, 4.4721e+21, 1.5956e+25],\n",
              "        [4.7399e+16, 2.3868e-06, 1.4838e-41, 1.5695e-43]])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)\n",
        "y = x.view(3, 4)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlaMJ32mUyqY",
        "outputId": "159544fe-bfa5-4222-a516-8bd8c8f316dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4068e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00,        nan, 4.7399e+16],\n",
            "        [4.4721e+21, 1.5956e+25, 4.7399e+16, 2.3868e-06, 1.4838e-41, 0.0000e+00]])\n",
            "tensor([[1.4068e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00],\n",
            "        [       nan, 4.7399e+16, 4.4721e+21, 1.5956e+25],\n",
            "        [4.7399e+16, 2.3868e-06, 1.4838e-41, 0.0000e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# or if you want to operate on non-contigous tensors\n",
        "print(x)\n",
        "y = x.reshape(3, 4)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7ymH2Kok74I",
        "outputId": "61766dfb-98e4-4914-fb6d-d1b6bd906374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4062e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00,        nan, 1.5975e-43],\n",
            "        [4.4721e+21, 1.5956e+25, 4.7399e+16, 2.3868e-06, 1.4838e-41, 1.5695e-43]])\n",
            "tensor([[1.4062e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00,        nan, 1.5975e-43],\n",
            "        [4.4721e+21, 1.5956e+25, 4.7399e+16, 2.3868e-06, 1.4838e-41, 1.5695e-43]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH9FdmzfkADq",
        "outputId": "65a50b4f-55db-459f-8ae5-2ee3d41f88c6"
      },
      "source": [
        "# transposing a tensor (columns become rows)\n",
        "torch.transpose(y, 0, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.4068e-34,        nan, 4.7399e+16],\n",
              "        [0.0000e+00, 4.7399e+16, 2.3868e-06],\n",
              "        [3.3631e-44, 4.4721e+21, 1.4838e-41],\n",
              "        [0.0000e+00, 1.5956e+25, 0.0000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# re-arrange dimensions of a tensor\n",
        "x = torch.rand(640, 480, 3)\n",
        "y = x.permute(2,0,1)\n",
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEPbXNgPmQrf",
        "outputId": "bc76ad37-34e2-496f-9da4-cc556fd058e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 640, 480])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Operations on tensors (matrix algebra)"
      ],
      "metadata": {
        "id": "HlLgKe9_To_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch math and linear algebra is also similar to Numpy. Operators are overridden so you can use standard math operators (`+`,`-`, etc.) and expect a tensor as a result. See pytorch documentation for a complete list of available functions."
      ],
      "metadata": {
        "id": "uvBojFuVLUpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(0.,5.)\n",
        "print(torch.sum(x))\n",
        "print(torch.sum(torch.exp(x)))\n",
        "print(torch.mean(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLTHfaTWLfQ0",
        "outputId": "15f6f057-6418-42b5-cb70-b5f6353e0ca9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.)\n",
            "tensor(85.7910)\n",
            "tensor(2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# element-wise additon with mathematical symbols\n",
        "torch.ones(1,2) + torch.ones(1,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0iRmesUFwiv",
        "outputId": "0543a393-9fc1-4541-dafe-3b2645e58976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# or with built-in methods\n",
        "torch.add(torch.ones(1,2), torch.ones(1,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1BJmrv9T1cs",
        "outputId": "3970b32b-a010-4fab-bb39-d0619be0cedf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summing alog the colums\n",
        "print(y)\n",
        "describe(torch.sum(y, dim=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "li9wj5SlUKFa",
        "outputId": "b152593b-9ac4-4cba-eed8-a4acea5c2921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4068e-34, 0.0000e+00, 3.3631e-44, 0.0000e+00],\n",
            "        [       nan, 4.7399e+16, 4.4721e+21, 1.5956e+25],\n",
            "        [4.7399e+16, 2.3868e-06, 1.4838e-41, 0.0000e+00]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([4])\n",
            "Values: \n",
            "tensor([       nan, 4.7399e+16, 4.4721e+21, 1.5956e+25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# or rows\n",
        "describe(torch.sum(y, dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ug9viDYVheC",
        "outputId": "a2e2846b-c6ac-4d9f-b616-7e29a6d1308d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3])\n",
            "Values: \n",
            "tensor([1.4068e-34,        nan, 4.7399e+16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# matrix multiplication\n",
        "describe(torch.mm())"
      ],
      "metadata": {
        "id": "me3OuZ88cRVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# access the max value\n",
        "x.max().item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAgM44ZpiU4G",
        "outputId": "5ca2111c-4266-4d6b-8ce1-ae3897de215c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Broadcasting"
      ],
      "metadata": {
        "id": "FZJ_UZfdm2yq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Borrowed from NumPy, broadcasting allows to perform operations between a tensor and a smaller tensor. You can broadcast across two tensors if, starting backward from their trailing dimensions: \n",
        "- the two dimensions are equal\n",
        "- one of the dimensions is 1"
      ],
      "metadata": {
        "id": "N3QJP7a_nGRt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU vs CPU tensors"
      ],
      "metadata": {
        "id": "OcobxzOsgmMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors can be copied between CPU and GPU. It is important that everything involved in a calculation is on the same device. \n",
        "\n",
        "By default, PyTorch tensors are created to be used by a CPU."
      ],
      "metadata": {
        "id": "PyfwFzjfg46b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_tensor = torch.rand(2)\n",
        "cpu_tensor.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOjCCW_JhTMI",
        "outputId": "82319306-593a-41f0-ac5f-493e08da35c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When doing linear algebra operations it make sense to utilize a GPU. To use a GPU, you need to first allocate the tensor on the GPU’s memory. Access to GPUs is provided via CUDA API that was created by NVIDIA and is limited to use only NVIDIA GPUs."
      ],
      "metadata": {
        "id": "gEZ77o7Jhtu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in colab you need to change runtime environment for this to work\n",
        "# transfer a tensor to a GPU\n",
        "gpu_tensor = cpu_tensor.to(\"cuda\")\n",
        "gpu_tensor.device"
      ],
      "metadata": {
        "id": "5Z1syqE6hu_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3,2)\n",
        "# copy to GPU\n",
        "y = x.cuda()\n",
        "# copy back to CPU\n",
        "z = y.cpu()\n",
        "# get CPU tensor as numpy array\n",
        "# cannot get GPU tensor as numpy array directly\n",
        "try:\n",
        "    y.numpy()\n",
        "except RuntimeError as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "rxw6RSLSMMvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Operations between GPU and CPU tensors will fail. Operations require all arguments to be on the same device."
      ],
      "metadata": {
        "id": "Ku6Gsm-OMSs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3,5)  # CPU tensor\n",
        "y = torch.rand(5,4).cuda()  # GPU tensor\n",
        "try:\n",
        "    torch.mm(x,y)  # Operation between CPU and GPU fails\n",
        "except TypeError as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "X-yiu2toMT2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy to CPU if on GPU\n",
        "if y.is_cuda:\n",
        "    y = y.cpu()\n",
        "    print(y, y.dtype)"
      ],
      "metadata": {
        "id": "FGPmQaUUMf-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A convenient method is `new`, which creates a new tensor on the same device as another tensor. It should be used for creating tensors whenever possible."
      ],
      "metadata": {
        "id": "-NCKUovuNN41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.rand(3,2)\n",
        "x2 = x1.new(1,2)  # create cpu tensor\n",
        "print(x2)\n",
        "x1 = torch.rand(3,2).cuda()\n",
        "x2 = x1.new(1,2)  # create cuda tensor\n",
        "print(x2)"
      ],
      "metadata": {
        "id": "InPBfti-NTsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be device agnostic and write code that works whether it’s on the GPU or the CPU:"
      ],
      "metadata": {
        "id": "ctVdpI5Uiynf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "x = torch.rand(3, 3).to(device)\n",
        "describe(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMb0t0hIi8L7",
        "outputId": "640d0c89-311a-4184-a9d0-d41c8a9d3d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[0.6116, 0.3273, 0.7642],\n",
            "        [0.8197, 0.4571, 0.1784],\n",
            "        [0.9317, 0.1341, 0.0010]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computations will break if both tensors involved are not used on the same device. It's computationally expensive to move data back and forth and therefore typical procedure involves doing parallelizable operations on the GPU and transfer the final results to the CPU.\n",
        "\n",
        "In case you have multiple GPUs, the best practice is to use the CUDA_VISIBLE_DEVICES as environment variable when executing the Python training script."
      ],
      "metadata": {
        "id": "690qwbr5jofb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CUDA_VISIBLE_DEVICES=0,1,2,3 python main.py"
      ],
      "metadata": {
        "id": "evc_7qPkkqmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculations executed on the GPU can be many times faster than numpy. However, numpy is still optimized for the CPU and many times faster than python `for loops`. Numpy calculations may be faster than GPU calculations for small arrays due to the cost of interfacing with the GPU."
      ],
      "metadata": {
        "id": "HkiFEDcxNbdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import timeit\n",
        "# Create random data\n",
        "x = torch.rand(1000,64)\n",
        "y = torch.rand(64,32)\n",
        "number = 10000  # number of iterations\n",
        "\n",
        "def square():\n",
        "    z=torch.mm(x, y) # dot product (mm=matrix multiplication)\n",
        "\n",
        "# Time CPU\n",
        "print('CPU: {}ms'.format(timeit(square, number=number)*1000))\n",
        "# Time GPU\n",
        "x, y = x.cuda(), y.cuda()\n",
        "print('GPU: {}ms'.format(timeit(square, number=number)*1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSZPHMIXNctB",
        "outputId": "b00f80e9-fdde-44ef-c438-f997dad46c1e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU: 547.9166890000045ms\n",
            "GPU: 2637.6892470000257ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Differentiation within a network\n",
        "\n"
      ],
      "metadata": {
        "id": "M2IOumsgcqSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apart from storing the data itself, PyTorch tensors handle the intermediate results of gradient computation by setting *requires_grad* flag to True at instantiation time. This is required for model training.\n",
        "\n",
        "At the end of a forward pass through the network, a single scalar (*loss*) is used to compute the backward pass which is initiated by using the *backward()* method. During the backward propagation, gradient vectors are computed for all tensors which where involved during the forward pass.  \n",
        "\n",
        "It's possible to access the gradients for all nodes of the computational graph by using the *.grad* variable of a tensor. The network optimizer uses this variable to update the values of the parameters (model weights). \n",
        "\n",
        "What you need to remember :\n",
        "\n",
        "- Tensors you are differentiating with respect to must have `requires_grad=True`\n",
        "- Call `.backward()` on scalar variables you are differentiating\n",
        "- To differentiate a vector, sum it first"
      ],
      "metadata": {
        "id": "bOJFl35yc_o8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-qxIBeglG5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67d94190-9a1b-416b-dea7-722e6cff29d4"
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x.grad)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we require a scalar to apply the backward method to it\n",
        "x = x.mean()\n",
        "x.backward()"
      ],
      "metadata": {
        "id": "5buOeXPNfJLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da7df21-9175-4692-d256-b2798ea4ac26"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Differentiation accumulates gradients. This is sometimes what you want and sometimes not.\n",
        "\n",
        "**Make sure to zero gradients between batches if performing gradient descent or you will get strange results!**"
      ],
      "metadata": {
        "id": "r81jqyTlOuaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a variable\n",
        "x=torch.tensor(torch.arange(0.,4.), requires_grad=True)\n",
        "# Differentiate\n",
        "torch.sum(x**2).backward()\n",
        "print(x.grad)\n",
        "# Differentiate again (accumulates gradient)\n",
        "torch.sum(x**2).backward()\n",
        "print(x.grad)\n",
        "# Zero gradient before differentiating\n",
        "x.grad.data.zero_()\n",
        "torch.sum(x**2).backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXbUM3JaO8nZ",
        "outputId": "5751091f-d308-40b6-a81b-46e1b87a0df1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 2., 4., 6.])\n",
            "tensor([ 0.,  4.,  8., 12.])\n",
            "tensor([0., 2., 4., 6.])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that a Tensor with gradient cannot be exported to numpy directly:"
      ],
      "metadata": {
        "id": "sv4aW5JVPZA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor(torch.arange(0.,4.), requires_grad=True)\n",
        "x.numpy() # raises an exception"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "Xio95tV5PdA9",
        "outputId": "b873d371-a116-4ebc-81fd-04673716fad7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-96e3ca8fef1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# raises an exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason is that pytorch remembers the graph of all computations to perform differenciation. To be integrated to this graph the raw data is wrapped internally to the Tensor class.\n",
        "\n",
        "You can detach the tensor from the graph using the .detach() method, which returns a tensor with the same data but requires_grad set to False."
      ],
      "metadata": {
        "id": "U4sPF9NZP_Ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.detach().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHEmD4nuQInW",
        "outputId": "054e71b2-dd95-405a-dfb8-0739ae171ca9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another reason to use this method is that updating the graph can use a lot of memory. If you are in a context where you have a differentiable tensor that you don't need to differentiate, think of detaching it from the graph."
      ],
      "metadata": {
        "id": "gGRv_7oGQRJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Network modules"
      ],
      "metadata": {
        "id": "wwfaPUBERmK_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data sets and data loaders**"
      ],
      "metadata": {
        "id": "pxJChYeUoHLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch has developed standard conventions of interacting with training data that make it fairly consistent to work with, whether you’re working with images, text, or audio. Those convetions include *datasets* and *data loaders*.\n",
        "\n",
        "A Dataset is a PyTorch class which allows to \"pre-package\" training data into the right format. We might apply any manipulation to the data here and implement different methods such as get.length and get.label."
      ],
      "metadata": {
        "id": "106XH8NzIEB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to give a better idea how to define a custom set\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# define your own dataset class by inheriting from PyTorch Dataset \n",
        "class dataset(Dataset):\n",
        "\n",
        "  def __init__(self, path_to_data):\n",
        "    raise NotImplementedError\n",
        "    '''Load data from disk, pre-process it, and compile it\n",
        "    to feature tensors and labels\n",
        "    \n",
        "    self.features = []\n",
        "    self.labels = []\n",
        "    \n",
        "    file_list = dir(path_to_data)\n",
        "    \n",
        "    for i, file in enumerate(file_list)\n",
        "    \n",
        "      normalize data\n",
        "      extract features here\n",
        "    \n",
        "      self.features = append(feature_from_file)\n",
        "      self.labels = append(flabel_from_file)'''\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    raise NotImplementedError\n",
        "    ''' Extract a single item (label + feature tensor) from the\n",
        "    dataset \n",
        "    \n",
        "    return self.features[index], self.labels[index]\n",
        "    \n",
        "    '''\n",
        "  \n",
        "  def __len__(self):\n",
        "    raise NotImplementedError\n",
        "    ''' Returns the length of all training features \n",
        "    \n",
        "    return len(self.features)\n",
        "    \n",
        "    '''\n",
        "\n",
        "# load your training data from disc into the dataset class\n",
        "train_data = dataset(path_to_data)"
      ],
      "metadata": {
        "id": "pptP4-56p04-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A data loader is there to load *batches* of training data into the training pipeline. For that the loader uses the *\\__getitem\\__* method from the Dataset class. The loader also controls the *number of worker* pocesses and whether the training data should be shuffeled. By default, data loaders set the batch size to 1."
      ],
      "metadata": {
        "id": "tTNYdo7SqUNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a DataLoader for the training data (before a training loop)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=4, shuffle=True)"
      ],
      "metadata": {
        "id": "Oh4Sw1LVwnTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same procedure has to be performed for the *validation* and *test* data sets."
      ],
      "metadata": {
        "id": "EDdl0uBYx5Pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The network**\n"
      ],
      "metadata": {
        "id": "jwGEVtRpoLmk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `torch.nn` module provides basic layers. To create a custom network, we inherit from a class called *torch.nn.Network* and fill out the \\__init\\__ and forward methods:"
      ],
      "metadata": {
        "id": "2-izSE3uyksq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in this example the activations functions are included in the forward method\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(12288, 84) # called Dense in Keras\n",
        "    self.fc2 = nn.Linear(84, 50)\n",
        "    self.fc3 = nn.Linear(50,2)\n",
        "  \n",
        "  def forward(self):\n",
        "    x = x.view(-1, 12288)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "# initialize the model\n",
        "simplenet = SimpleNet()"
      ],
      "metadata": {
        "id": "Urq4_-3Zy3M5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatevely, we can use the `nn.Sequential` class."
      ],
      "metadata": {
        "id": "M6c203tVR8GG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in this example the activation functions are included in the layers object and\n",
        "# the forward method just calls it - seems to be more clean\n",
        "\n",
        "class SimpleConvNet(nn.Module):\n",
        "  '''\n",
        "    Simple Convolutional Neural Network\n",
        "  '''\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "      nn.Conv2d(1, 10, kernel_size=3),\n",
        "      nn.ReLU(),\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(1094500, 50),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(50, 20),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(20, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''Forward pass'''\n",
        "    return self.layers(x)\n",
        "\n",
        "# initialize the model\n",
        "simpleconvnet = SimpleConvNet()"
      ],
      "metadata": {
        "id": "0FBb1c4kz4U6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To access network's parameters we use the **parameters()** method, which returns a python generator."
      ],
      "metadata": {
        "id": "WQEopwSRSnaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in simpleconvnet.parameters():\n",
        "    print(param)"
      ],
      "metadata": {
        "id": "gvO4aCzgS3lN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train the network, we need an optimizer:"
      ],
      "metadata": {
        "id": "ZRmN57l-3EMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize optimizer (before a training loop)\n",
        "optimizer = torch.optim.Adam(simpleconvnet.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "lEUfq3mw3JTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training loop"
      ],
      "metadata": {
        "id": "s4Lb_Tm44aYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to define a training loop for the network. Here are the required pieces:"
      ],
      "metadata": {
        "id": "lnnCTSWg1oX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# configuration options for the training\n",
        "epochs = 1\n",
        "batch_size = 16\n",
        "learning_rate = 1e-4\n",
        "loss_function = nn.CrossEntropyLoss() # includes the softmax activation\n",
        "\n",
        "# initialize data loaders for train, test data\n",
        "# initialize the optimizer\n",
        "\n",
        "# initialize the neural network\n",
        "\n",
        "# set fixed random number seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# outer loop for the epoch numbers\n",
        "for epoch in range(epochs):\n",
        "  # inner loop for the mini-batches\n",
        "  for batch in train_loader:\n",
        "    optimizer.zero_grad() # reset gradients to zero before new batch\n",
        "    features, labels = batch\n",
        "    output = simpleconvnet(features)\n",
        "    loss = loss_function(output, labels)\n",
        "    loss.backward() # compute gradients\n",
        "    optimizer.step() # adjust the weights based on the gradients"
      ],
      "metadata": {
        "id": "DYhpp-Ku1xzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.CrossEntropyLoss does both the softmax and the actual cross-entropy : given $output$ of size $(n,d)$ and $y$ of size $n$ and values in $0,1,...,d-1$, it computes $\\sum_{i=0}^{n-1}log(s[i,y[i]])$ where $s[i,j] = \\frac{e^{output[i,j]}}{\\sum_{j'=0}^{d-1}e^{output[i,j']}}$\n",
        "\n",
        "You can also compose nn.LogSoftmax and nn.NLLLoss to get the same result. Note that all these use the log-softmax rather than the softmax, for stability in the computations."
      ],
      "metadata": {
        "id": "Uc6k4s-QTmW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function2 = nn.NLLLoss()\n",
        "sf = nn.LogSoftmax()\n",
        "output = simpleconvnet(features)\n",
        "loss = loss_function2(sf(output), labels)"
      ],
      "metadata": {
        "id": "DXXkq_F5Tum_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To perform the backward pass, we just execute loss.backward() which updates gradients in all differentiable tensors in the graph."
      ],
      "metadata": {
        "id": "2oQFK2otUXSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to train on a GPU\n",
        "simpleconvnet.to(device)"
      ],
      "metadata": {
        "id": "iiMZu_Bn7GgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving and loading"
      ],
      "metadata": {
        "id": "Sq6zK1yaVXZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# saving a model\n",
        "torch.save(simplenet, \"path\")\n",
        "\n",
        "# loading a model\n",
        "simplenet = torch.load(\"path\")"
      ],
      "metadata": {
        "id": "OMq56BAvAw2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This stores both the parameters and the structure of the model to a file. This might be a problem if you change the structure of the model at a later point. For this reason, it’s more common to save a model’s state_dict instead. This is a standard Python dict that contains the maps of each layer’s parameters in the model."
      ],
      "metadata": {
        "id": "cRNx1QEHBGwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get dictionary of keys to weights using `state_dict`\n",
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Linear(28*28,256),\n",
        "    torch.nn.Sigmoid(),\n",
        "    torch.nn.Linear(256,10))\n",
        "print(net.state_dict().keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ0AXnBXVnRd",
        "outputId": "0b992342-17a1-4ce8-cbc8-4e46861dfd57"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['0.weight', '0.bias', '2.weight', '2.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), \"path\")\n",
        "\n",
        "# load\n",
        "simplenet = SimpleNet()\n",
        "simplenet_state_dict = torch.load(\"/tmp/simplenet\")\n",
        "simplenet.load_state_dict(simplenet_state_dict)"
      ],
      "metadata": {
        "id": "JtajsgJFBNzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The benefit here is that if you extend the model in some fashion, you can supply a strict=False parameter to load_state_dict that assigns parameters to layers in the model that do exist in the state_dict, but does not fail if the loaded state_dict has layers missing or added from the model’s current structure.\n",
        "\n",
        "Models can be saved to a disk during a training run and reloaded at another point so that training can continue where you left off."
      ],
      "metadata": {
        "id": "iVyDE4-EBkWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment logging with Tensorboard"
      ],
      "metadata": {
        "id": "kwmbSyOovlfM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorBoard is a logging and visualization tool that is a popular choice for training deep learning models. Although initially published for TensorFlow, TensorBoard is also integrated in PyTorch allowing us to easily use it. First, let’s import it below."
      ],
      "metadata": {
        "id": "LNt4sjlBvvh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tensorboard logger from PyTorch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Load tensorboard extension for Jupyter Notebook, only need to start TB in the notebook\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "kR80vE7sXJhz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last line is required if you want to run TensorBoard directly in the Jupyter Notebook. Otherwise, you can start TensorBoard from the terminal."
      ],
      "metadata": {
        "id": "n4kQ8pDaXStd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start the logging process by creating a new object, `writer = SummaryWriter(...)`, where we specify the directory in which the logging file should be saved.\n",
        "\n",
        "With this object, we can log different aspects of our model by calling functions of the style `writer.add_...`. \n",
        "\n",
        "For example, we can visualize the computation graph with the function `writer.add_graph`, or add a scalar value like the loss with `writer.add_scalar`.\n",
        "\n",
        "Let’s adapt the training loop with adding a TensorBoard logger below."
      ],
      "metadata": {
        "id": "zwIyRvM5XYc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# configuration options for the training\n",
        "epochs = 1\n",
        "batch_size = 16\n",
        "learning_rate = 1e-4\n",
        "loss_function = nn.CrossEntropyLoss() # includes the softmax activation\n",
        "\n",
        "# Create TensorBoard logger\n",
        "writer = SummaryWriter('experiment_logs')\n",
        "model_plotted = False\n",
        "\n",
        "# initialize data loaders for train, test data\n",
        "# initialize the optimizer\n",
        "\n",
        "# initialize the neural network\n",
        "\n",
        "# set fixed random number seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# outer loop for the epoch numbers\n",
        "for epoch in range(epochs):\n",
        "  epoch_loss = 0.0\n",
        "  # inner loop for the mini-batches\n",
        "  for batch in train_loader:\n",
        "    features, labels = batch\n",
        "\n",
        "    # For the very first batch, we visualize the computation graph in TensorBoard\n",
        "    if not model_plotted:\n",
        "      writer.add_graph(simpleconvnet, features)\n",
        "      model_plotted = True\n",
        "    \n",
        "    output = simpleconvnet(features)\n",
        "    loss = loss_function(output, labels)\n",
        "    optimizer.zero_grad() # reset gradients to zero before computing new grads\n",
        "    loss.backward() # compute gradients\n",
        "    optimizer.step() # adjust the weights based on the gradients\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "  \n",
        "  # Add average loss to TensorBoard\n",
        "  epoch_loss /= len(train_loader)\n",
        "  writer.add_scalar('training_loss',\n",
        "                    epoch_loss,\n",
        "                    global_step = epoch + 1)"
      ],
      "metadata": {
        "id": "16ZO1eeKXtW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Lightning"
      ],
      "metadata": {
        "id": "2CaTppULPKze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Lightning is a wrapper library which allows to re-pack the training loop inside a single module. This doesn't really makes you write less code, but you get out a better structured code.\n",
        "\n",
        "For a gentle introduction see https://towardsdatascience.com/from-pytorch-to-pytorch-lightning-a-gentle-introduction-b371b7caaf09\n",
        "\n",
        "Altough, the author suggests to use LightningModule for model and update fuctions, LightningDataModule for DataLoaders, and the Lightning's trainer function to train the model, there are examples where DataLoaders are put inside the LightningModule, which makes it kind of more slick.\n",
        "\n",
        "Lightning also handles logging into TensorBoard, and saving model checkpoints automatically with minimal code overhead from our side."
      ],
      "metadata": {
        "id": "dXdOBhDvPmXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Lightning\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError:\n",
        "    # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
        "    !pip install --quiet pytorch-lightning\n",
        "    import pytorch_lightning as pl"
      ],
      "metadata": {
        "id": "O8-gU-yqkD5x"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the seed\n",
        "pl.seed_everything(42)"
      ],
      "metadata": {
        "id": "5we3Su0wkUmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch Lightning, we define `pl.LightningModule`s (inheriting from `torch.nn.Module`) that organize our code into 5 main sections:\n",
        "\n",
        "- Initialization (__init__), where we create all necessary parameters/models\n",
        "\n",
        "- Optimizers (configure_optimizers) where we create the optimizers, learning rate scheduler, etc.\n",
        "\n",
        "- Training loop (training_step) where we only have to define the loss calculation for a single batch (the loop of optimizer.zero_grad(), loss.backward() and optimizer.step(), as well as any logging/saving operation, is done in the background)\n",
        "\n",
        "- Validation loop (validation_step) where similarly to the training, we only have to define what should happen per step\n",
        "\n",
        "- Test loop (test_step) which is the same as validation, only on a test set."
      ],
      "metadata": {
        "id": "YTCJCZjglDvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFARModule(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, model_name, model_hparams, optimizer_name, optimizer_hparams):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            model_name - Name of the model/CNN to run. Used for creating the model (see function below)\n",
        "            model_hparams - Hyperparameters for the model, as dictionary.\n",
        "            optimizer_name - Name of the optimizer to use. Currently supported: Adam, SGD\n",
        "            optimizer_hparams - Hyperparameters for the optimizer, as dictionary. This includes learning rate, weight decay, etc.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Exports the hyperparameters to a YAML file, and create \"self.hparams\" namespace\n",
        "        self.save_hyperparameters()\n",
        "        # Create model\n",
        "        self.model = create_model(model_name, model_hparams)\n",
        "        # Create loss module\n",
        "        self.loss_module = nn.CrossEntropyLoss()\n",
        "        # Example input for visualizing the graph in Tensorboard\n",
        "        self.example_input_array = torch.zeros((1, 3, 32, 32), dtype=torch.float32)\n",
        "\n",
        "    def forward(self, imgs):\n",
        "        # Forward function that is run when visualizing the graph\n",
        "        return self.model(imgs)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # We will support Adam or SGD as optimizers.\n",
        "        if self.hparams.optimizer_name == \"Adam\":\n",
        "            # AdamW is Adam with a correct implementation of weight decay (see here for details: https://arxiv.org/pdf/1711.05101.pdf)\n",
        "            optimizer = optim.AdamW(\n",
        "                self.parameters(), **self.hparams.optimizer_hparams)\n",
        "        elif self.hparams.optimizer_name == \"SGD\":\n",
        "            optimizer = optim.SGD(self.parameters(), **self.hparams.optimizer_hparams)\n",
        "        else:\n",
        "            assert False, f\"Unknown optimizer: \\\"{self.hparams.optimizer_name}\\\"\"\n",
        "\n",
        "        # We will reduce the learning rate by 0.1 after 100 and 150 epochs\n",
        "        scheduler = optim.lr_scheduler.MultiStepLR(\n",
        "            optimizer, milestones=[100, 150], gamma=0.1)\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # \"batch\" is the output of the training data loader.\n",
        "        imgs, labels = batch\n",
        "        preds = self.model(imgs)\n",
        "        loss = self.loss_module(preds, labels)\n",
        "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
        "\n",
        "        # Logs the accuracy per epoch to tensorboard (weighted average over batches)\n",
        "        self.log('train_acc', acc, on_step=False, on_epoch=True)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss  # Return tensor to call \".backward\" on\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        preds = self.model(imgs).argmax(dim=-1)\n",
        "        acc = (labels == preds).float().mean()\n",
        "        # By default logs it per epoch (weighted average over batches)\n",
        "        self.log('val_acc', acc)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        preds = self.model(imgs).argmax(dim=-1)\n",
        "        acc = (labels == preds).float().mean()\n",
        "        # By default logs it per epoch (weighted average over batches), and returns it afterwards\n",
        "        self.log('test_acc', acc)"
      ],
      "metadata": {
        "id": "MSEKfEsQljgY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another important part of PyTorch Lightning is the concept of callbacks. Callbacks are self-contained functions that contain the non-essential logic of your Lightning Module. They are usually called after finishing a training epoch, but can also influence other parts of your training loop.\n",
        "\n",
        "For instance, we will use the following two pre-defined callbacks: `LearningRateMonitor` and `ModelCheckpoint`. The learning rate monitor adds the current learning rate to our TensorBoard, which helps to verify that our learning rate scheduler works correctly.\n",
        "\n",
        "The model checkpoint callback allows you to customize the saving routine of your checkpoints. For instance, how many checkpoints to keep, when to save, which metric to look out for, etc. We import them below:"
      ],
      "metadata": {
        "id": "luliO7-pl3LK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint"
      ],
      "metadata": {
        "id": "FCREMi01mD9q"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To allow running multiple different models with the same Lightning module, we define a function below that maps a model name to the model class. At this stage, the dictionary `model_dict` is empty, but we will fill it throughout the notebook with our new models."
      ],
      "metadata": {
        "id": "Xd_3BkWpnVfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict = {}\n",
        "\n",
        "def create_model(model_name, model_hparams):\n",
        "    if model_name in model_dict:\n",
        "        return model_dict[model_name](**model_hparams)\n",
        "    else:\n",
        "        assert False, f\"Unknown model name \\\"{model_name}\\\". Available models are: {str(model_dict.keys())}\""
      ],
      "metadata": {
        "id": "-rbGU4Wynb5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, to use the activation function as another hyperparameter in our model, we define a “name to function” dict below:"
      ],
      "metadata": {
        "id": "Bh4D91WgniCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "act_fn_by_name = {\n",
        "    \"tanh\": nn.Tanh,\n",
        "    \"relu\": nn.ReLU,\n",
        "    \"leakyrelu\": nn.LeakyReLU,\n",
        "    \"gelu\": nn.GELU\n",
        "}"
      ],
      "metadata": {
        "id": "7PVID_bQnkwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we pass the classes or objects directly as an argument to the Lightning module, we couldn’t take advantage of PyTorch Lightning’s automatically hyperparameter saving and loading.\n",
        "\n",
        "Besides the `Lightning module`, the second most important module in PyTorch Lightning is the `Trainer`. The trainer is responsible to execute the training steps defined in the Lightning module and completes the framework. Similar to the Lightning module, you can override any key part that you don’t want to be automated, but the default settings are often the best practice to do. The most important functions we use below are:\n",
        "\n",
        "- `trainer.fit`: Takes as input a lightning module, a training dataset, and an (optional) validation dataset. This function trains the given module on the training dataset with occasional validation (default once per epoch, can be changed)\n",
        "\n",
        "- `trainer.test`: Takes as input a model and a dataset on which we want to test. It returns the test metric on the dataset.\n",
        "\n",
        "For training and testing, we don’t have to worry about things like setting the model to eval mode (model.eval()) as this is all done automatically. See below how we define a training function for our models:"
      ],
      "metadata": {
        "id": "10VPoNNKn3FA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model_name, save_name=None, **kwargs):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        model_name - Name of the model you want to run. Is used to look up the class in \"model_dict\"\n",
        "        save_name (optional) - If specified, this name will be used for creating the checkpoint and logging directory.\n",
        "    \"\"\"\n",
        "    if save_name is None:\n",
        "        save_name = model_name\n",
        "\n",
        "    # Create a PyTorch Lightning trainer with the generation callback\n",
        "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, save_name),                          # Where to save models\n",
        "                         gpus=1 if str(device)==\"cuda:0\" else 0,                                             # We run on a single GPU (if possible)\n",
        "                         max_epochs=180,                                                                     # How many epochs to train for if no patience is set\n",
        "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),  # Save the best checkpoint based on the maximum val_acc recorded. Saves only weights and not optimizer\n",
        "                                    LearningRateMonitor(\"epoch\")],                                           # Log learning rate every epoch\n",
        "                         enable_progress_bar=True)                                                           # Set to False if you do not want a progress bar\n",
        "    trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n",
        "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
        "\n",
        "    # Check whether pretrained model exists. If yes, load it and skip training\n",
        "    pretrained_filename = os.path.join(CHECKPOINT_PATH, save_name + \".ckpt\")\n",
        "    if os.path.isfile(pretrained_filename):\n",
        "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
        "        model = CIFARModule.load_from_checkpoint(pretrained_filename) # Automatically loads the model with the saved hyperparameters\n",
        "    else:\n",
        "        pl.seed_everything(42) # To be reproducable\n",
        "        model = CIFARModule(model_name=model_name, **kwargs)\n",
        "        trainer.fit(model, train_loader, val_loader)\n",
        "        model = CIFARModule.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n",
        "\n",
        "    # Test best model on validation and test set\n",
        "    val_result = trainer.test(model, val_loader, verbose=False)\n",
        "    test_result = trainer.test(model, test_loader, verbose=False)\n",
        "    result = {\"test\": test_result[0][\"test_acc\"], \"val\": val_result[0][\"test_acc\"]}\n",
        "\n",
        "    return model, result"
      ],
      "metadata": {
        "id": "s-Q-FfUwoTwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Examples"
      ],
      "metadata": {
        "id": "GulMyhDsR2rd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feed forward network for image classification**"
      ],
      "metadata": {
        "id": "pQWENpp-Pn07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save images.csv that contains an URL list from https://github.com/falloutdurham/beginners-pytorch-deep-learning/tree/master/chapter2 and copy it in the Colab session.\n",
        "\n",
        "Use then the following script to download the images (1394) into the Colab session (takes over 20 minutes!):"
      ],
      "metadata": {
        "id": "S7vTYyNwQcC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import urllib3\n",
        "from urllib.parse import urlparse\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import shutil\n",
        "\n",
        "from urllib3.util import Retry\n",
        "\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "classes = [\"cat\", \"fish\"]\n",
        "set_types = [\"train\", \"test\", \"val\"]\n",
        "\n",
        "def download_image(url, klass, data_type):\n",
        "    basename = os.path.basename(urlparse(url).path)\n",
        "    filename = \"{}/{}/{}\".format(data_type, klass, basename)\n",
        "    if not os.path.exists(filename):\n",
        "        try: \n",
        "            http = urllib3.PoolManager(retries=Retry(connect=1, read=1, redirect=2))\n",
        "            with http.request(\"GET\", url, preload_content=False) as resp, open(\n",
        "                filename, \"wb\"\n",
        "            ) as out_file:\n",
        "                if resp.status == 200:\n",
        "                    shutil.copyfileobj(resp, out_file)\n",
        "                else:\n",
        "                    print(\"Error downloading {}\".format(url))\n",
        "            resp.release_conn()\n",
        "        except:\n",
        "            print(\"Error downloading {}\".format(url))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if not os.path.exists(\"images.csv\"):\n",
        "        print(\"Error: can't find images.csv!\")\n",
        "        sys.exit(0)\n",
        "\n",
        "    # get args and create output directory\n",
        "    imagesDF = pd.read_csv(\"images.csv\")\n",
        "\n",
        "    for set_type, klass in list(itertools.product(set_types, classes)):\n",
        "        path = \"./{}/{}\".format(set_type, klass)\n",
        "        if not os.path.exists(path):\n",
        "            print(\"Creating directory {}\".format(path))\n",
        "            os.makedirs(path)\n",
        "\n",
        "    print(\"Downloading {} images\".format(len(imagesDF)))\n",
        "\n",
        "    result = [\n",
        "        download_image(url, klass, data_type)\n",
        "        for url, klass, data_type in zip(\n",
        "            imagesDF[\"url\"], imagesDF[\"class\"], imagesDF[\"type\"]\n",
        "        )\n",
        "    ]\n",
        "    sys.exit(0)"
      ],
      "metadata": {
        "id": "FEVpLYV1QOeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating training, validation, and test sets for the image data\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "train_data_path = \"train\"\n",
        "\n",
        "transforms = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225] )\n",
        "    ])\n",
        "\n",
        "train_data = torchvision.datasets.ImageFolder(root=train_data_path,\n",
        "                                              transform=transforms)\n",
        "\n",
        "val_data_path = \"val\"\n",
        "val_data = torchvision.datasets.ImageFolder(root=val_data_path,\n",
        "                                            transform=transforms)\n",
        "\n",
        "test_data_path = \"test\"\n",
        "test_data = torchvision.datasets.ImageFolder(root=test_data_path,\n",
        "                                            transform=transforms)"
      ],
      "metadata": {
        "id": "UbY_REywWpWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating DataLoaders\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size=64\n",
        "train_data_loader = DataLoader(train_data, batch_size=batch_size)\n",
        "val_data_loader  = DataLoader(val_data, batch_size=batch_size)\n",
        "test_data_loader  = DataLoader(test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "o5m7pzZGXtlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# network\n",
        "class SimpleNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(12288, 84) # called Dense in Keras\n",
        "    self.fc2 = nn.Linear(84, 50)\n",
        "    self.fc3 = nn.Linear(50,2)\n",
        "  \n",
        "  def forward(self):\n",
        "    x = x.view(-1, 12288)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "# initialize the model\n",
        "simplenet = SimpleNet()"
      ],
      "metadata": {
        "id": "1jLgpGbXY3Pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(simplenet.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Hy1GkTs5Zib7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training loop in a single training function:"
      ],
      "metadata": {
        "id": "1sR0TA_07UAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=0):\n",
        "  for epoch in range(epochs):\n",
        "    training_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      inputs, target = batch\n",
        "      inputs = inputs.to(device)\n",
        "      target = targets.to(device)\n",
        "      output = model(inputs)\n",
        "      loss = loss_fn(output, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      training_loss += loss.data.item()\n",
        "    training_loss /= len(train_iterator)\n",
        "      \n",
        "    model.eval()\n",
        "    num_correct = 0\n",
        "    num_examples = 0\n",
        "    for batch in val_loader:\n",
        "      inputs, targets = batch\n",
        "      inputs = inputs.to(device)\n",
        "      output = model(inputs)\n",
        "      targets = targets.to(device)\n",
        "      loss = loss_fn(output,targets)\n",
        "      valid_loss += loss.data.item()\n",
        "      correct = torch.eq(torch.max(F.softmax(output), dim=1)[1],\n",
        "                         target).view(-1)\n",
        "      num_correct += torch.sum(correct).item()\n",
        "      num_examples += correct.shape[0]\n",
        "    valid_loss /= len(valid_iterator)\n",
        "    \n",
        "    print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss,\n",
        "    valid_loss, num_correct / num_examples))"
      ],
      "metadata": {
        "id": "aZzASgJTIE0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(simplenet, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, test_data_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "g3JJcU2JBk9B",
        "outputId": "47c485cd-afde-4bae-d422-bb8d4f09ff15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-133-e229ee12f99e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimplenet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-126-ad414c61fd48>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loss_fn, train_loader, val_loader, epochs, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \"\"\"\n\u001b[1;32m    229\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2894\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2895\u001b[0m     raise UnidentifiedImageError(\n\u001b[0;32m-> 2896\u001b[0;31m         \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2897\u001b[0m     )\n\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BufferedReader name='train/cat/052cat.jpg'>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example with prebuilt data set**"
      ],
      "metadata": {
        "id": "fzLHK0AobsMB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aYJLSkQZbw56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face with PyTorch\n",
        "\n"
      ],
      "metadata": {
        "id": "1NI78k428mml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hugging Face transformers is a Python library which allows to use pre-trained large language models and fine-tune them on your own data set using its Trainer API (see https://huggingface.co/course/chapter3/1?fw=pt).\n",
        "\n",
        "Following this approach, tuning/training a PyTorch model becomes as easy as using Keras' model.fit(). See the following example:"
      ],
      "metadata": {
        "id": "tM-eclpnSOC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning\n",
        "!pip install tensorboard\n",
        "!pip install nlp\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "Ko2w1CY_-gvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "import nlp\n",
        "import transformers"
      ],
      "metadata": {
        "id": "tHSmBOV4-uMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IMDBSentimentClassifier(pl.LightningModule):\n",
        "    \n",
        "    # initilize the model and model loss\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # load a re-trained BERT model from HF transfomers\n",
        "        self.model = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "        # cross-entropy loss from PyTorch\n",
        "        self.loss = torch.nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \n",
        "        # load BERT tokenizer from HF transformers\n",
        "        tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # convert the text field to token ids and add to the data set items\n",
        "        # text sequences also get normalized here\n",
        "        def _tokenize(x):\n",
        "            x['token_ids'] = tokenizer.batch_encode_plus(\n",
        "                    x['text'], \n",
        "                    max_length=32,\n",
        "                    truncation=True, \n",
        "                    padding=True)\n",
        "            return x\n",
        "\n",
        "        # load IMDB data set from HF nlp and split it\n",
        "        def _prepare_ds(split):\n",
        "            ds = nlp.load_dataset('imdb', split='train[:10%]')\n",
        "            ds = ds.map(_tokenize, batched=True)\n",
        "            ds.set_format(type='torch', columns=['token_ids', 'label'])\n",
        "            return ds\n",
        "\n",
        "        self.train_ds, self.test_ds = map(_prepare_ds, ('train', 'test'))\n",
        "\n",
        "    def forward(self, token_ids):\n",
        "        mask = (token_ids != 0).float()\n",
        "        logits, = self.model(token_ids, mask)\n",
        "        return logits\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        logits = self.forward(batch['token_ids'])\n",
        "        loss = self.loss(logits, batch['label']).mean()\n",
        "        return {'loss': loss, 'log': {'train_loss': loss}}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        logits = self.forward(batch['token_ids'])\n",
        "        loss = self.loss(logits, batch['label'])\n",
        "        acc = (logits.argmax(-1) == batch['label']).float()\n",
        "        return {'loss': loss, 'acc': acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        loss = torch.cat([o['loss'] for o in outputs], 0).mean()\n",
        "        acc = torch.cat([o['acc'] for o in outputs], 0).mean()\n",
        "        out = {'val_loss': loss, 'val_acc': acc}\n",
        "        return {**out, 'log': out}\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(\n",
        "                self.train_ds,\n",
        "                batch_size=8,\n",
        "                drop_last=True,\n",
        "                shuffle=True,\n",
        "                )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(\n",
        "                self.test_ds,\n",
        "                batch_size=8,\n",
        "                drop_last=False,\n",
        "                shuffle=True,\n",
        "                )\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.SGD(\n",
        "            self.parameters(),\n",
        "            lr=1e-2,\n",
        "            momentum=0.9,\n",
        "        )\n",
        "    \n",
        "def main(_):\n",
        "    model = IMDBSentimentClassifier()\n",
        "    trainer = pl.Trainer(\n",
        "        default_root_dir='root/logs',\n",
        "        gpus=(1 if torch.cuda.is_available() else 0),\n",
        "        max_epochs=10,\n",
        "        logger=pl.loggers.TensorBoardLogger('root/logs/', name='imdb', version=0),\n",
        "    )\n",
        "    trainer.fit(model)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main(_)"
      ],
      "metadata": {
        "id": "3HMXSEXd-xp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, in case you need any additional customizations for your training you can still utilize all of the underlying PyTorch functionality and implement your own training loop (see https://huggingface.co/course/chapter3/4?fw=pt)."
      ],
      "metadata": {
        "id": "rKMrIKe9_tA-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using AWS Sagemaker"
      ],
      "metadata": {
        "id": "WhNvJaLMwqzB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO_DO"
      ],
      "metadata": {
        "id": "kFCzJc1Gwurl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hfHuNeC9wt6p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}