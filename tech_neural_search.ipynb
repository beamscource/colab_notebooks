{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "UzGD0heIoDce",
        "69YVggHLEKBj",
        "SYWWmfY7zmsW",
        "itK1X-qjk5BC",
        "8a5j1FtwzMsC"
      ],
      "authorship_tag": "ABX9TyMk6asUcP5SMlEC3U7YZMnB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beamscource/colab_notebooks/blob/main/tech_neural_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General introduction: semantic search"
      ],
      "metadata": {
        "id": "UzGD0heIoDce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- semantic search is a general term including keyword search, structured search, and natural language search\n",
        "- question answering (natural language search) on text/on knowledge graphs is a quite old concept\n",
        "- in the context of deep learning, people speak of vector/neural search when talking about semantic search\n",
        "- however, semantic search is a single use case for modern vector search applications  "
      ],
      "metadata": {
        "id": "UC1C10_72pNA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Semantic search survey from 2016 (pre-Transformer)**\n",
        "\n",
        "- https://documentcloud.adobe.com/gsuiteintegration/index.html?state=%7B%22ids%22%3A%5B%221cTZYIdOauz4FR9ZPCrqGqKimAY8ympVU%22%5D%2C%22action%22%3A%22open%22%2C%22userId%22%3A%22116509636905417906901%22%2C%22resourceKeys%22%3A%7B%7D%7D"
      ],
      "metadata": {
        "id": "IIGdIcSjoM0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neural search**\n",
        "- https://livebook.manning.com/book/ai-powered-search/welcome/v-14/\n",
        "- https://github.com/treygrainger/ai-powered-search"
      ],
      "metadata": {
        "id": "zzPxP5eKLfQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neural QA**\n",
        "- https://arxiv.org/pdf/2002.06612.pdf - survey article from 2020\n",
        "- https://en.wikipedia.org/wiki/Question_answering\n",
        "- https://www.deepset.ai/blog/why-trained-qa-model-needs-data\n",
        "- https://towardsdatascience.com/understanding-dense-passage-retrieval-dpr-system-bce5aee4fd40\n",
        "- https://arxiv.org/abs/2110.03142\n",
        "- https://ad-publications.cs.uni-freiburg.de/KI_broccoli_quality_BBH_2017.pdf"
      ],
      "metadata": {
        "id": "pH_xz_r6aurV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OSS software for vector/neural search**\n",
        "\n",
        "- https://github.com/deepset-ai/haystack - Question Answering or semantic document search, combine with other open-source projects like Huggingface's Transformers, Elasticsearch, or Milvus. Written in Python.\n",
        "\n",
        "- https://github.com/neuml/txtai - similarity search and complex NLP-driven data extractions\n",
        "- https://github.com/jina-ai/jina\n",
        "- https://github.com/allenai/document-qa - research project, not production ready\n",
        "- https://github.com/victordibia/neuralqa\n",
        "- https://pythonrepo.com/tag/question-answering"
      ],
      "metadata": {
        "id": "BmKmAh-Yowz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Haystack (search framework for text)"
      ],
      "metadata": {
        "id": "itK1X-qjk5BC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "List of all Haystack tutorials:\n",
        "\n",
        "- https://haystack.deepset.ai/tutorials/first-qa-system\n",
        "- https://github.com/deepset-ai/haystack-tutorials/tree/main/tutorials\n",
        "\n",
        "**Haystack allows to build all kinds of search applications. It doesn't have to be a vector search application. What makes it a vector search application is not Haystack itself, but rather the type of DB used in the backend.**"
      ],
      "metadata": {
        "id": "Ay2Se3ODn_Bb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure to change the runtime to 'GPU'..."
      ],
      "metadata": {
        "id": "_GO2o7ZRlC8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check GPU\n",
        "\n",
        "! nvidia-smi"
      ],
      "metadata": {
        "id": "PhqGj1sOlCMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install haystack\n",
        "! pip install --upgrade pip\n",
        "! pip install git+https://github.com/deepset-ai/haystack.git#egg=farm-haystack[colab]"
      ],
      "metadata": {
        "id": "1mcHHdQJlV8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We configure how logging messages should be displayed and which log level should be used before importing Haystack.\n",
        "\n",
        "Default log level in basicConfig is WARNING so the explicit parameter is not necessary but can be changed easily:"
      ],
      "metadata": {
        "id": "8TwK-LTHmTqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
      ],
      "metadata": {
        "id": "FqqCF4KmmXT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Document store**\n",
        "\n",
        "Haystack finds answers to queries within the documents stored in a **DocumentStore**.\n",
        "\n",
        "The current implementations of DocumentStore include\n",
        "- ElasticsearchDocumentStore\n",
        "- FAISSDocumentStore\n",
        "- SQLDocumentStore (using SQLite)\n",
        "- InMemoryDocumentStore\n",
        "\n",
        "Find more infor at https://haystack.deepset.ai/components/document-store\n"
      ],
      "metadata": {
        "id": "s_L1ZtgLmhOi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We recommended Elasticsearch as it comes preloaded with following features:\n",
        "\n",
        "**Full-text queries**\n",
        "\n",
        "https://www.elastic.co/guide/en/elasticsearch/reference/current/full-text-queries.html\n",
        "\n",
        "**BM25 retrieval**\n",
        "\n",
        "https://www.elastic.co/de/elasticon/conf/2016/sf/improved-text-scoring-with-bm25\n",
        "\n",
        "**Vector storage for text embeddings**\n",
        "\n",
        "https://www.elastic.co/guide/en/elasticsearch/reference/7.6/dense-vector.html\n",
        "\n",
        "If you are unable to setup an Elasticsearch instance, then follow this tutorial for using SQL/InMemory document stores: https://github.com/deepset-ai/haystack-tutorials/blob/main/tutorials/03_Basic_QA_Pipeline_without_Elasticsearch.ipynb\n",
        "\n",
        "**Hint**: This tutorial creates a new document store instance with Wikipedia articles on Game of Thrones. However, you can configure Haystack to work with your existing document stores.\n"
      ],
      "metadata": {
        "id": "EP2M7fe2m2yn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install and start an elasticsearch server\n",
        "!wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
        "!tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
        "!chown -R daemon:daemon elasticsearch-7.9.2\n",
        "!sudo -u daemon -- elasticsearch-7.9.2/bin/elasticsearch"
      ],
      "metadata": {
        "id": "gCGL2Rhdvy2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from haystack.document_stores import ElasticsearchDocumentStore\n",
        "\n",
        "# Get the host where Elasticsearch is running, default to localhost\n",
        "host = os.environ.get(\"ELASTICSEARCH_HOST\", \"localhost\")\n",
        "document_store = ElasticsearchDocumentStore(host=host, username=\"\", password=\"\", index=\"document\")"
      ],
      "metadata": {
        "id": "tP8zpC8GwLv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In-Memory Document Store\n",
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "document_store = InMemoryDocumentStore()"
      ],
      "metadata": {
        "id": "57ztY4F0mvkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternatively, uncomment the following to use the SQLite Document Store:\n",
        "\n",
        "# from haystack.document_stores import SQLDocumentStore\n",
        "# document_store = SQLDocumentStore(url=\"sqlite:///qa.db\")"
      ],
      "metadata": {
        "id": "_bBhapNVoTgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing of documents**\n",
        "\n",
        "\n",
        "Haystack provides a customizable pipeline for:\n",
        "\n",
        "- converting files into texts\n",
        "- cleaning texts\n",
        "- splitting texts\n",
        "- writing them to a Document Store"
      ],
      "metadata": {
        "id": "rOBGZcJ5ojR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial, we download Wikipedia articles about **Game of Thrones**, apply a basic cleaning function, and index them in Elasticsearch."
      ],
      "metadata": {
        "id": "-5rcBg3toxZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.utils import clean_wiki_text, convert_files_to_docs, fetch_archive_from_http\n",
        "\n",
        "\n",
        "# Let's first fetch some documents that we want to query\n",
        "# Here: 517 Wikipedia articles for Game of Thrones\n",
        "doc_dir = \"data/tutorial1\"\n",
        "s3_url = \"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/wiki_gameofthrones_txt1.zip\"\n",
        "fetch_archive_from_http(url=s3_url, output_dir=doc_dir)\n",
        "\n",
        "# Convert files to dicts\n",
        "# You can optionally supply a cleaning function that is applied to each doc (e.g. to remove footers)\n",
        "# It must take a str as input, and return a str.\n",
        "docs = convert_files_to_docs(dir_path=doc_dir, clean_func=clean_wiki_text, split_paragraphs=True)\n",
        "\n",
        "# We now have a list of dictionaries that we can write to our document store.\n",
        "# If your texts come from a different source (e.g. a DB), you can of course skip convert_files_to_dicts() and create the dictionaries yourself.\n",
        "# The default format here is:\n",
        "# {\n",
        "#    'content': \"<DOCUMENT_TEXT_HERE>\",\n",
        "#    'meta': {'name': \"<DOCUMENT_NAME_HERE>\", ...}\n",
        "# }\n",
        "# (Optionally: you can also add more key-value-pairs here, that will be indexed as fields in Elasticsearch and\n",
        "# can be accessed later for filtering or shown in the responses of the Pipeline)\n",
        "\n",
        "# Let's have a look at the first 3 entries:\n",
        "print(docs[:3])\n",
        "\n",
        "# Now, let's write the dicts containing documents to our DB.\n",
        "document_store.write_documents(docs)"
      ],
      "metadata": {
        "id": "N_R5UV-con-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retriever**\n",
        "\n",
        "Retrievers help narrowing down the scope for the Reader to smaller units of text where a given question could be answered. They use some simple but fast algorithm.\n",
        "\n",
        "- Elasticsearch's default **BM25 algorithm** (https://en.wikipedia.org/wiki/Okapi_BM25)\n",
        "- Customize the **BM25Retriever** with custom queries (e.g. boosting) and filters\n",
        "- Use **TfidfRetriever** in combination with a SQL or InMemory Document store for simple prototyping and debugging\n",
        "- Use **EmbeddingRetriever** to find candidate documents based on the similarity of embeddings (e.g. created via Sentence-BERT)\n",
        "- Use **DensePassageRetriever** to use different embedding models for passage and query (see https://github.com/deepset-ai/haystack-tutorials/blob/main/tutorials/06_Better_Retrieval_via_Embedding_Retrieval.ipynb)"
      ],
      "metadata": {
        "id": "rb4pJLXtp57C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import BM25Retriever\n",
        "\n",
        "retriever = BM25Retriever(document_store=document_store)"
      ],
      "metadata": {
        "id": "w_ld3OZUsDjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative: An in-memory TfidfRetriever based on Pandas dataframes for building quick-prototypes with SQLite document store.\n",
        "\n",
        "from haystack.nodes import TfidfRetriever\n",
        "retriever = TfidfRetriever(document_store=document_store)"
      ],
      "metadata": {
        "id": "Kpe7JUAMsJ8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reader**\n",
        "\n",
        "\n",
        "A Reader **extracts the k best answers** from the texts returned by the retriever. Readers are based on **powerful, but slower deep learning models.\n",
        "\n",
        "Haystack currently supports Readers based on the frameworks **FARM and Transformers**.\n",
        "\n",
        "*With both you can either load a local model or one from Hugging Face's model hub (https://huggingface.co/models).\n",
        "\n",
        "**Tutorial for a FARM reader**: a medium sized RoBERTa QA model using a Reader based on FARM (https://huggingface.co/deepset/roberta-base-squad2)\n",
        "\n",
        "**Alternative Reader**: **TransformersReader** (leveraging the pipeline of the Transformers package)\n",
        "\n",
        "**Alternatives Models**: e.g. \"distilbert-base-uncased-distilled-squad\" (fast) or \"deepset/bert-large-uncased-whole-word-masking-squad2\" (good accuracy)\n",
        "\n",
        "**Hint**: You can adjust the model to return \"no answer possible\" with the no_ans_boost. Higher values mean the model prefers \"no answer possible\""
      ],
      "metadata": {
        "id": "CyidrDoysB34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import FARMReader\n",
        "\n",
        "# Load a  local model or any of the QA models on\n",
        "# Hugging Face's model hub (https://huggingface.co/models)\n",
        "\n",
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)"
      ],
      "metadata": {
        "id": "hsXXRA_breFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import TransformersReader\n",
        "# reader = TransformersReader(model_name_or_path=\"distilbert-base-uncased-distilled-squad\", tokenizer=\"distilbert-base-uncased\", use_gpu=-1)"
      ],
      "metadata": {
        "id": "Ipc618MLuPTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pipeline**\n",
        "\n",
        "With a Haystack Pipeline you can stick together your building blocks to a search pipeline. Under the hood, Pipelines are Directed Acyclic Graphs (DAGs) that you can easily customize for your own use cases.\n",
        "\n",
        "To speed things up, Haystack also comes with a few **predefined Pipelines**. One of them is the **ExtractiveQAPipeline** that combines a retriever and a reader to answer our questions.\n",
        "\n",
        "You can learn more about Pipelines here https://haystack.deepset.ai/docs/latest/pipelinesmd"
      ],
      "metadata": {
        "id": "ESZDpJ9_uccH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.pipelines import ExtractiveQAPipeline\n",
        "\n",
        "pipe = ExtractiveQAPipeline(reader, retriever)"
      ],
      "metadata": {
        "id": "Dz7k5c9XuqbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ask a question**"
      ],
      "metadata": {
        "id": "OlPUCWbVu6Wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can configure how many candidates the Reader and Retriever shall return\n",
        "# The higher top_k_retriever, the better (but also the slower) your answers.\n",
        "prediction = pipe.run(\n",
        "    query=\"Who is the father of Arya Stark?\", params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
        ")"
      ],
      "metadata": {
        "id": "Az_rzKeNu4oA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction = pipe.run(query=\"Who created the Dothraki vocabulary?\", params={\"Reader\": {\"top_k\": 5}})\n",
        "# prediction = pipe.run(query=\"Who is the sister of Sansa?\", params={\"Reader\": {\"top_k\": 5}})"
      ],
      "metadata": {
        "id": "pEW9Mzy1w3v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the predictions\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "pprint(prediction)\n",
        "\n",
        "# Sample output:\n",
        "# {\n",
        "#     'answers': [ <Answer: answer='Eddard', type='extractive', score=0.9919578731060028, offsets_in_document=[{'start': 608, 'end': 615}], offsets_in_context=[{'start': 72, 'end': 79}], document_id='cc75f739897ecbf8c14657b13dda890e', meta={'name': '454_Music_of_Game_of_Thrones.txt'}}, context='...' >,\n",
        "#                  <Answer: answer='Ned', type='extractive', score=0.9767240881919861, offsets_in_document=[{'start': 3687, 'end': 3801}], offsets_in_context=[{'start': 18, 'end': 132}], document_id='9acf17ec9083c4022f69eb4a37187080', meta={'name': '454_Music_of_Game_of_Thrones.txt'}}, context='...' >,\n",
        "#                  ...\n",
        "#                ]\n",
        "#     'documents': [ <Document: content_type='text', score=0.8034909798951382, meta={'name': '332_Sansa_Stark.txt'}, embedding=None, id=d1f36ec7170e4c46cde65787fe125dfe', content='\\n===\\'\\'A Game of Thrones\\'\\'===\\nSansa Stark begins the novel by being betrothed to Crown ...'>,\n",
        "#                    <Document: content_type='text', score=0.8002150354529785, meta={'name': '191_Gendry.txt'}, embedding=None, id='dd4e070a22896afa81748d6510006d2', 'content='\\n===Season 2===\\nGendry travels North with Yoren and other Night's Watch recruits, including Arya ...'>,\n",
        "#                    ...\n",
        "#                  ],\n",
        "#     'no_ans_gap':  11.688868522644043,\n",
        "#     'node_id': 'Reader',\n",
        "#     'params': {'Reader': {'top_k': 5}, 'Retriever': {'top_k': 5}},\n",
        "#     'query': 'Who is the father of Arya Stark?',\n",
        "#     'root_node': 'Query'\n",
        "# }"
      ],
      "metadata": {
        "id": "lUB4v6yEvd3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.utils import print_answers\n",
        "\n",
        "# Change `minimum` to `medium` or `all` to raise the level of detail\n",
        "print_answers(prediction, details=\"minimum\")"
      ],
      "metadata": {
        "id": "nPzlAXOPxCw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generative and long-form QA**\n",
        "\n",
        "- https://haystack.deepset.ai/tutorials/retrieval-augmented-generation\n",
        "- https://haystack.deepset.ai/tutorials/lfqa\n",
        "- https://www.youtube.com/watch?v=O9lrWt15wH8"
      ],
      "metadata": {
        "id": "EZdZXnKxk99X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Useful resources:\n",
        "\n",
        "- https://haystack.deepset.ai/guides/guides-overview\n",
        "- https://www.deepset.ai/weaviate-vector-search-engine-integration\n",
        "- https://www.deepset.ai/germanquad\n",
        "- https://haystack.deepset.ai/components/annotation\n",
        "\n",
        "- https://www.youtube.com/watch?v=ZdS_V1A5r44&list=PLIUOU7oqGTLhmJsdJo67WynQ-mbRXkL9R&index=5\n",
        "\n",
        "- https://github.com/deepset-ai/rasa-haystack - Combine a Rasa Chatbot with Haystack\n",
        "\n",
        "- https://medium.com/@duerr.sebastian/gain-valuable-corporate-insights-from-a-10-k-report-in-5-easy-steps-with-dense-passage-retrieval-8e0cac743c7d"
      ],
      "metadata": {
        "id": "sG7G-QZ_xSF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Demo app with Haystack**\n",
        "- https://www.deepset.ai/blog/building-a-rest-api-for-question-answering-with-haystack\n",
        "- https://github.com/deepset-ai/haystack/issues/664\n",
        "- https://github.com/anakin87/haystack/tree/722c850bc7aee028b53f88831ddfa176fcb0432a\n",
        "- https://hub.docker.com/r/deepset/haystack-streamlit-ui"
      ],
      "metadata": {
        "id": "hcRr2-_TEoDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Langchain and Llama-Index for generative QA"
      ],
      "metadata": {
        "id": "b62Jj2VLKIrf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://langchain.readthedocs.io/en/latest/_modules/langchain/llms/huggingface_pipeline.html?highlight=HUggingFace#\n",
        "- https://github.com/jerryjliu/gpt_index\n",
        "- see this YT channel https://www.youtube.com/@jamesbriggs"
      ],
      "metadata": {
        "id": "T7SpFQQ8KNFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Research on neural QA"
      ],
      "metadata": {
        "id": "i5rLvanCphTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LLMs + Graphs**\n",
        "\n",
        "- https://arxiv.org/abs/2104.06378 - LM + GNN\n",
        "- Tutorial https://ai.stanford.edu/blog/qagnn/\n",
        "- https://pris-nlp.github.io/en/publication/large-scale-relation-learning-for-question-answering-over-knowledge-bases-with-pre-trained-language-models/\n",
        "\n",
        "**Generative QA**\n",
        "- https://ai.facebook.com/blog/longform-qa/\n",
        "\n",
        "- https://aclanthology.org/D19-5827/ - Generalizing QA with LMs\n",
        "\n",
        "- https://paperswithcode.com/task/question-answering - list of papers"
      ],
      "metadata": {
        "id": "SuqdMHQB2pHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Amazon**"
      ],
      "metadata": {
        "id": "a1fpibLDpkZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- QA on KGs\n",
        "- NLU as QA https://www.amazon.science/publications/language-model-is-all-you-need-natural-language-understanding-as-question-answering"
      ],
      "metadata": {
        "id": "81bk5bdlp_cy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Microsoft**"
      ],
      "metadata": {
        "id": "y7g3Ch7687mQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Knowledge-infused language models for commen sense QA**\n",
        "\n",
        "https://www.youtube.com/watch?v=18jub4NRzwY"
      ],
      "metadata": {
        "id": "5PnLbxtw94id"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Group**\n",
        "\n",
        "- 10-13 PhDs\n",
        "- publications and push into productions (MS Cognitive Services)"
      ],
      "metadata": {
        "id": "UIImiqy2XtFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problems**\n",
        "\n",
        "- the models get too big to be used in practice (hosting and fine-tuning)\n",
        "- for 175B GPT-3 model you require 24 V100 GPUs at least\n",
        "- no path to human-level intelligence"
      ],
      "metadata": {
        "id": "RTX5TnZf-GNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**External attention to knowledge**\n",
        "\n",
        "- a LM learns rather the grammatical patterns (how to express)\n",
        "- knowledge (what to express) is not present in the question itself\n",
        "- the possibilities to encode knowledge in LLMs is inefficient\n",
        "    - during training it tries to \"memorize\" grammar, facts, knowledge etc\n",
        "    - larger models memorize more, but not enough\n",
        "- alternative to precise knowledge store: knowledge graphs\n",
        "\n",
        "**Caounter proposal**\n",
        "\n",
        "- use basic LM to capture grammar and basic understanding, delegate the task of memorizing facts from the learning task to external knowledge sources\n",
        "- leverage external knowledge that is unlimited wrt volume and up-to-dateness\n",
        "- knowledge is any information absent from the input, but is required to generate the output\n",
        "- external knowledge can be stored in:\n",
        "  - knowledge graphs\n",
        "  - dictionaries (definitions)\n",
        "  - free text (e.g., Wikipedia)\n",
        "  - other specific LMs output\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "10tXIIpw96EM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to integrate external knowledge into LMs?**\n",
        "\n",
        "1. ground input text into related knowledge\n",
        "2. represent the knowledge\n",
        "3. fuse the representation into LM\n",
        "\n",
        "1.\n",
        "  - we don't need all the information from the external knowledge\n",
        "  - use string matching or entity-recognition, entity-linking or information retrieval to destill important parts from the question\n",
        "  - identify concepts and relations that are in the knowlede source\n",
        "\n",
        "2.\n",
        "  - external knowledge has to be represented in a uniform format for the LM to consume\n",
        "  - text format using canonnical forms of entities in the knowledge graph, or descriptions and definitions from a dictionary, or numerical text embeddings\n",
        "  - example: cumpute graph embeddings with GNN from a knowledge graph and then return the node embedding corresponding to the entity/concept apearing in the question\n",
        "\n",
        "3.\n",
        "  - if knowledge is represented as text, simply concatenate it with the input\n",
        "  - for embeddings, append the graph embedding to the text word embedding of a concept\n",
        "  - use attention to re-weight importance of the embeddings\n",
        "\n"
      ],
      "metadata": {
        "id": "k38dlzfRJ_HW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Case study: commensense QA**\n",
        "\n",
        "**Paper**: https://arxiv.org/abs/2112.03254\n",
        "\n",
        "- Question: Where would I not want a fox [to be]?\n",
        "- 5 choices with the correct being *hen house*\n",
        "- commensence knowledge: foxes eat hens, we don't want to loose hens \n",
        "\n",
        "**With LM only**\n",
        "- concatenate the question with each choice: 87 confidence score\n",
        "- depends on the data set of the language model\n",
        "\n",
        "**ConceptNet**\n",
        "\n",
        "ConceptNet is a freely-available semantic network, designed to help computers understand the meanings of words that people use.\n",
        "\n",
        "- https://conceptnet.io/\n",
        "- was used to construct the data set for commensense QA\n",
        "- we try to establish a relation between the entity from the question (fox) with the entities from the answer choices (hen house etc)\n",
        "- appending (after a separator) question entity, choice entity, triple from the graph after the query\n",
        "- improves the accuracy by 7 percent\n",
        "\n",
        "**Dictionary**\n",
        "\n",
        "- no biases based on the frequency of word tokens like LMs\n",
        "- we look up definitions (fox, hen house) of the question entity and response entity and append the text to the query\n",
        "\n",
        "**Training data**\n",
        "\n",
        "- we don't throw away the training set after training because the model didn't memorized everything\n",
        "- use IR to get top 5-10 training instances pairs of similar questions (if X = Where is Mona Lisa? and y = ???, then x1 = Where are Davinci's paintings?, y1 = Louvre, x2 = What is in the Louvre? y2 = Paintings.... )and append them to the query\n",
        "- BART base performs better than BART large with this addition\n",
        "- 98.8 accuracy\n",
        "- we can incorporate more training data from related tasks to improve the accuracy even further\n",
        "- MS got over human-parity"
      ],
      "metadata": {
        "id": "3DzvC76wM2oN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions**\n",
        "\n",
        "- triplets, definitions, and external training data are used during fine-tuning and inference stage of the task\n",
        "- how to understand whether the external training data is relevant (related to few-shot learning and zero-shot learning)\n",
        "  - label a minimum amount of training data (100 pairs)\n",
        "  - find similar data sets"
      ],
      "metadata": {
        "id": "9T9WRBfQSlNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Case study: Multilingual QA**\n",
        "\n",
        "**Paper**: https://aclanthology.org/2022.findings-acl.255.pdf\n",
        "\n",
        "- most knowledge sources are in English\n",
        "\n",
        "**Summary**\n",
        "- Translate-Retrieve-Translate (TRT)\n",
        "- same stuff but with a translation step\n",
        "- triplet: canonnical form, neighbour node, relation (entity-linking)\n",
        "- additional augmentation with free text\n",
        "- used BM25 for the retrival step\n",
        "- use GPT-3 to generate simple definitions (with additional examples)\n",
        "- dictionaries proofed to be most useful\n",
        "- "
      ],
      "metadata": {
        "id": "kIgerSEOSkKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Case study: Dict-BERT**\n",
        "\n",
        "**Paper**: https://arxiv.org/abs/2110.06490\n",
        "\n",
        "- include definitions during **pre-training**\n",
        "- BERT base + dictionaries\n",
        "- adopt masked language training\n",
        "- first task: append difinitions for masked and related words to the training examples\n",
        "- second task: increase the similarity between positive and negative pairs\n",
        "- third task: is the given definition describes the masked word"
      ],
      "metadata": {
        "id": "koOJg3BlWC9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jina AI (a more general search framework, e.g. for images and audio)"
      ],
      "metadata": {
        "id": "8a5j1FtwzMsC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://medium.com/jina-ai/faceted-knowledge-base-search-with-jina-and-jcloud-d7c92f963033\n",
        "- https://colab.research.google.com/github/jina-ai/workshops/blob/docs-add-text-to-image-notebook/text2image/Image_Search_via_Text.ipynb#scrollTo=uxtgtYD9zTB4"
      ],
      "metadata": {
        "id": "35t4g5YlzPhn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FAISS"
      ],
      "metadata": {
        "id": "6OkTw20X47Tk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://faiss.ai/\n",
        "\n",
        "Faiss is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning."
      ],
      "metadata": {
        "id": "V0Q1Bt-r5AC6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector databases"
      ],
      "metadata": {
        "id": "69YVggHLEKBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A vector database is a hard requirement to make modern vector search application. Irrespective of wether you're interested in text, images, or multi-modal applications:"
      ],
      "metadata": {
        "id": "rmizGZAyGrFf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overview of vector DBs:\n",
        "- https://dmitry-kan.medium.com/landscape-of-vector-databases-d241b279f486\n",
        "- Dmitry Kan on Weaviate podcast https://m.youtube.com/watch?v=1ebCUCUJraE#bottom-sheet\n",
        "- https://www.youtube.com/c/VectorPodcast\n",
        "\n",
        "- https://towardsdatascience.com/milvus-pinecone-vespa-weaviate-vald-gsi-what-unites-these-buzz-words-and-what-makes-each-9c65a3bd0696"
      ],
      "metadata": {
        "id": "FvNxGFiHEN29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://github.com/semi-technologies/weaviate - a low-latency vector search engine with out-of-the-box support for different media types (text, images, etc.). It offers Semantic Search, Question-Answer Extraction, Classification, Customizable Models (PyTorch/TensorFlow/Keras), etc. Built from scratch in Go, Weaviate stores both objects and vectors, allowing for combining vector search with structured filtering and the fault-tolerance of a cloud-native database, all accessible through GraphQL, REST, and various programming languages client.\n",
        "\n",
        "- https://github.com/milvus-io/milvus\n",
        "- https://github.com/qdrant/qdrant\n",
        "- https://qdrant.tech/benchmarks/single-node-speed-benchmark/\n",
        "- https://www.pinecone.io/learn/vector-database/\n"
      ],
      "metadata": {
        "id": "jwehYLhFLS8c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weaviate (database with QA capabilities)"
      ],
      "metadata": {
        "id": "SYWWmfY7zmsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction**\n",
        "\n",
        "See https://weaviate.io/developers/weaviate/current/core-knowledge/basics.html\n",
        "\n",
        "\n",
        "Weaviate is a database of the type search engine, and it’s specifically built to work with vector representations produced by machine learning models. Hence, Weaviate is a **vector search engine**.\n",
        "\n",
        "When working with a database, you want full CRUD support (https://en.wikipedia.org/wiki/Create,_read,_update_and_delete). Not all approximate nearest neighbor algorithms support this, and not all incumbent databases (/search engines) are optimized for this type of indexing.\n",
        "\n",
        "These reasons are -among others- the most important to why Weaviate exists You can also learn more about this by reading https://db-engines.com/en/blog_post/87\n",
        "\n",
        "**JSON objects as documents**\n",
        "\n",
        "We can save the information about an author like this:"
      ],
      "metadata": {
        "id": "h8GCgsbA8YK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"name\": \"Alice Munro\",\n",
        "    \"age\": 91,\n",
        "    \"born\": \"1931-07-10T00:00:00.0Z\",\n",
        "    \"wonNobelPrize\": true,\n",
        "    \"description\": \"Alice Ann Munro is a Canadian short story writer who won the Nobel Prize in Literature in 2013. Munro's work has been described as revolutionizing the architecture of short stories, especially in its tendency to move forward and backward in time.\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "v7RDuDBT95-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also attach vector representations to our data objects under a \"vector\" property, like this:"
      ],
      "metadata": {
        "id": "EFr4qfdR9-W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"id\": \"779c8970-0594-301c-bff5-d12907414002\",\n",
        "    \"class\": \"Author\",\n",
        "    \"properties\": {\n",
        "        \"name\": \"Alice Munro\",\n",
        "        (...)\n",
        "    },\n",
        "    \"vector\": [\n",
        "        -0.16147631,\n",
        "        -0.065765485,\n",
        "        -0.06546908\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "ZtPHs3iw-D0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weaviate groups all Authors under the Author class and place them in the same **class collection**. Weaviate can store multipe authors like this:"
      ],
      "metadata": {
        "id": "cF1JWVoT-RBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[{\n",
        "    \"id\": \"dedd462a-23c8-32d0-9412-6fcf9c1e8149\",\n",
        "    \"class\": \"Author\",\n",
        "    \"properties\": {\n",
        "        \"name\": \"Alice Munro\",\n",
        "        \"age\": 91,\n",
        "        \"born\": \"1931-07-10T00:00:00.0Z\",\n",
        "        \"wonNobelPrize\": true,\n",
        "        \"description\": \"Alice Ann Munro is a Canadian short story writer who won the Nobel Prize in Literature in 2013. Munro's work has been described as revolutionizing the architecture of short stories, especially in its tendency to move forward and backward in time.\"\n",
        "    },\n",
        "    \"vector\": [\n",
        "        -0.16147631,\n",
        "        -0.065765485,\n",
        "        -0.06546908\n",
        "    ]\n",
        "}, {\n",
        "    \"id\": \"779c8970-0594-301c-bff5-d12907414002\",\n",
        "    \"class\": \"Author\",\n",
        "    \"properties\": {\n",
        "        \"name\": \"Paul Krugman\",\n",
        "        \"age\": 69,\n",
        "        \"born\": \"1953-02-28T00:00:00.0Z\",\n",
        "        \"wonNobelPrize\": true,\n",
        "        \"description\": \"Paul Robin Krugman is an American economist and public intellectual, who is Distinguished Professor of Economics at the Graduate Center of the City University of New York, and a columnist for The New York Times. In 2008, Krugman was the winner of the Nobel Memorial Prize in Economic Sciences for his contributions to New Trade Theory and New Economic Geography.\"\n",
        "    },\n",
        "    \"vector\": [\n",
        "        -0.93070928,\n",
        "        -0.03782172,\n",
        "        -0.56288009\n",
        "    ]\n",
        "}]\n"
      ],
      "metadata": {
        "id": "eKZY5SSo-WhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every object stored has a UIID (https://en.wikipedia.org/wiki/Universally_unique_identifier)."
      ],
      "metadata": {
        "id": "qVz5oFuT-cLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In some cases we need to link data objects with each other. For example: “Paul Krugman writes for the New York Times”."
      ],
      "metadata": {
        "id": "4t6fE68p-w9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"id\": \"32d5a368-ace8-3bb7-ade7-9f7ff03eddb6\",\n",
        "    \"class\": \"Publication\",\n",
        "    \"properties\": {\n",
        "        \"name\": \"The New York Times\"\n",
        "    },\n",
        "    \"vector\": [...]\n",
        "}\n"
      ],
      "metadata": {
        "id": "wpQo86ES-1Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the UUID from the above object, to attach it to the Author like this (see \"writesFor\"):"
      ],
      "metadata": {
        "id": "2XhkohMC-7rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"id\": \"779c8970-0594-301c-bff5-d12907414002\",\n",
        "    \"class\": \"Author\",\n",
        "    \"properties\": {\n",
        "        \"name\": \"Paul Krugman\",\n",
        "        ...\n",
        "        \"writesFor\": [\n",
        "            {\n",
        "                \"beacon\": \"weaviate://localhost/32d5a368-ace8-3bb7-ade7-9f7ff03eddb6\",\n",
        "                \"href\": \"/v1/objects/32d5a368-ace8-3bb7-ade7-9f7ff03eddb6\"\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    \"vector\": [...]\n",
        "}\n"
      ],
      "metadata": {
        "id": "KMvEDLKF-9cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hrefs** and **beacons** are the locations within Weaviate, which allow us to retrieve cross-referenced objects. The difference between the two will become apparent while going through the getting started guide."
      ],
      "metadata": {
        "id": "tQqOzIzf_HRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Classes** and properties are **defined in the schema**.\n",
        "- **Every class has its own vector space**, which means that you can attach vectors from different models to different classes.\n",
        "- You can **link classes** (even if they use different embeddings) **by setting cross-references**.\n",
        "- You can configure module behavior, ANN index settings, reverse index types, etc. in the schema as well.\n",
        "\n",
        "Here is a getting-started guide for working with a schema https://weaviate.io/developers/weaviate/current/getting-started/schema.html"
      ],
      "metadata": {
        "id": "UQ4Rpofg_nCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a user, you have **two ways of generating vectors** for objects:\n",
        "\n",
        "- You render your vector from any model you have.\n",
        "- You use a Weaviate module with a prepackaged text2vec integration (we call them “vectorizers”, you can learn more about them here https://weaviate.io/developers/weaviate/current/modules/).\n",
        "\n",
        "- text2vec-transformers\n",
        "- text2vec-openai\n",
        "- text2vec-huggingface\n",
        "- text2vec-contextionary (custom FastText based vectorizer)\n",
        "- img2vec-neural\n",
        "- multi2vec-clip\n",
        "\n",
        "If you bring your own vectors to Weaviate, running *Weaviate stand-alone* is all you need. But in certain cases, you might want to use one of the prepackaged modules. For example, if you use OpenAI embeddings, you might want to use the OpenAI module, which automatically integrates with their embeddings-API. Or, if you have a use case where you want to use Sentence Transformers, you can use the Huggingface transformers module.\n",
        "\n",
        "Weaviate distinguishes **three types of modules**:\n",
        "\n",
        "1. *retrievers & vectorizers* are used to vectorize data objects and queries.\n",
        "2. *readers & generators* are used for reranking or processing the results.\n",
        "3. other modules are -often- non-ML, for example, the spell-check module.\n",
        "\n",
        "It's also possible to create custom modules (need knowledge of Go): https://weaviate.io/developers/weaviate/current/other-modules/custom-modules.html"
      ],
      "metadata": {
        "id": "wNvQSlc3AOcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weaviate console**\n",
        "\n",
        "The Weaviate console is part of the Weaviate Cloud Service and allows you to connect to any Weaviate instance and query it. For a getting-started guide see https://weaviate.io/developers/weaviate/current/core-knowledge/console.html\n",
        "\n",
        "We can query the database using the GraphQL-interface or -in some cases- the RESTful API.\n",
        "\n",
        "**Benchmarks**\n",
        "\n",
        "https://weaviate.io/developers/weaviate/current/benchmarks/\n",
        "\n",
        "**Monitoring**\n",
        "\n",
        "https://weaviate.io/developers/weaviate/current/configuration/monitoring.html\n",
        "\n"
      ],
      "metadata": {
        "id": "e2RSFVDjBjZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Querying data**\n",
        "\n",
        "- Weaviate’s main API is its GraphQL-API (https://www.youtube.com/watch?v=eIQh02xuVw4&ab_channel=Fireship)\n",
        "- Weaviate also has a RESTful API but it is used for other operations.\n",
        "- You can also use the clients to query Weaviate natively in your language of choice. The clients will automatically determine which API to use for the request. See https://weaviate.io/developers/weaviate/current/core-knowledge/clients.html\n",
        "\n",
        "The Weaviate Console contains a cool auto-complete feature to write queries easily.\n",
        "\n",
        "https://weaviate.io/developers/weaviate/current/getting-started/query.html"
      ],
      "metadata": {
        "id": "jlVFNdWlCQte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "List of tutorials:\n",
        "- https://weaviate.io/developers/weaviate/current/tutorials/index.html"
      ],
      "metadata": {
        "id": "Ihkm2taB0_Tr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://medium.com/keenious/knowledge-graph-search-of-60-million-vectors-with-weaviate-7964657ec911"
      ],
      "metadata": {
        "id": "9bYan6Fbzo4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QA with Weaviate**\n",
        "\n",
        "- https://weaviate.io/developers/weaviate/v1.11.0/reader-generator-modules/qna-transformers.html\n",
        "- https://zenodo.org/record/6518245#.Yy2eFXZBzZ8\n",
        "- https://www.youtube.com/watch?v=BkozaOnZpJI&ab_channel=Weaviate%E2%80%A2VectorSearchEngine - combine Weaviate and Haystack"
      ],
      "metadata": {
        "id": "mLK_ClKGL91-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Qdrant"
      ],
      "metadata": {
        "id": "Bs2aFHx_CuSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://blog.qdrant.tech/neural-search-tutorial-3f034ab13adc\n",
        "- https://qdrant.tech/demo/\n",
        "- https://github.com/qdrant/qdrant_demo\n",
        "- https://github.com/weaviate/partner-integration-examples/blob/main/docarray/.devcontainer/docker-compose.yml"
      ],
      "metadata": {
        "id": "F7P1Q2VyCwvk"
      }
    }
  ]
}