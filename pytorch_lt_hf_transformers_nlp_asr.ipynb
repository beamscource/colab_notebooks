{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beamscource/colab_notebooks/blob/main/pytorch_lt_hf_transformers_nlp_asr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Basic End-to-End Flow"
      ],
      "metadata": {
        "id": "-fFNN-jm7rPl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5HyjCAhV6jT"
      },
      "source": [
        "### Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-8pyuqhWl-s"
      },
      "source": [
        "PyTorch is a Python library which offers an **eager approach to differentiation** instead of defining static graphs, allowing for greater flexibility in the way networks are created, trained, and operated.\n",
        "\n",
        "Similar to DyNet and Chainer, and in contrast to static frameworks like TensorFlow/Theano/Caffe, models are not compiled before execution. \n",
        "\n",
        "PyTorch has two lineages. First, it derives many features and concepts from Torch, which was a Lua-based neural network library that dates back to 2002. Its other major parent is Chainer, created in Japan in 2015.\n",
        "\n",
        "The library also comes with modules that help with manipulating text, images, and audio (*torchtext*, *torchvision*, and *torchaudio*), along with built-in variants of popular architectures such as ResNet (with weights that can be downloaded to provide assistance with *transfer learning*).\n",
        "\n",
        "In 2022, about 85% of pre-trained models on HuggingFace are PyTorch models (https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2022/). Despite the fact that PyTorch is used by companies like Twitter, Salesforce, Tesla, Uber, and NVIDIA, the consensus seems to be that TF still offers better native deployment capabilities and that tf.keras might be better suited for a complete beginner."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the data"
      ],
      "metadata": {
        "id": "SJmeLyP_5-bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIWRmWai0uU0",
        "outputId": "373ecf4d-1603-4540-a5f5-66adc18342ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/_NN_NLP/PyTorch/datasets/shoes.zip . "
      ],
      "metadata": {
        "id": "lRVL9fUK1jEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip shoes.zip"
      ],
      "metadata": {
        "id": "_kt6cc0E5tb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define and train the model"
      ],
      "metadata": {
        "id": "WBuSVF4w6HKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "9o-D--oZ6KpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create data loaders\n",
        "\n",
        "transforms = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225] )\n",
        "    ])\n",
        "\n",
        "train_data_path = \"train\"\n",
        "train_data = torchvision.datasets.ImageFolder(root=train_data_path,\n",
        "                                              transform=transforms)\n",
        "\n",
        "val_data_path = \"val\"\n",
        "val_data = torchvision.datasets.ImageFolder(root=val_data_path,\n",
        "                                            transform=transforms)\n",
        "\n",
        "test_data_path = \"test\"\n",
        "test_data = torchvision.datasets.ImageFolder(root=test_data_path,\n",
        "                                            transform=transforms)\n",
        "\n",
        "batch_size=64\n",
        "train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_data_loader  = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
        "test_data_loader  = DataLoader(test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "WZ1cBQOU6QQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# define the network\n",
        "class SimpleNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(12288, 84) # input layer with the size 64*64*3 (input image)\n",
        "    self.fc2 = nn.Linear(84, 50)\n",
        "    self.fc3 = nn.Linear(50,3) # final layer with 3 units as output (for 3 categories)\n",
        "  \n",
        "  def forward(self, x): # bug was here\n",
        "    x = x.view(-1, 12288) # flatten the input image\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "# initialize the model\n",
        "simplenet = SimpleNet()\n",
        "simplenet.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En85lgR17dtZ",
        "outputId": "73bd9f16-e64a-4776-a11a-8c134d6852aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleNet(\n",
              "  (fc1): Linear(in_features=12288, out_features=84, bias=True)\n",
              "  (fc2): Linear(in_features=84, out_features=50, bias=True)\n",
              "  (fc3): Linear(in_features=50, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(simplenet.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "B8-3Lbfy8URJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZzASgJTIE0T"
      },
      "outputs": [],
      "source": [
        "# training loop\n",
        "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    \n",
        "    training_loss = 0.0 # set for the epoch\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    # start training for the given epoch\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    for inputs, labels in train_loader: # during each batch\n",
        "      \n",
        "      inputs = inputs.to(device) # move to GPU\n",
        "      labels = labels.to(device)\n",
        "      \n",
        "      predictions = model(inputs) # get model predictions for the batch\n",
        "      loss = loss_fn(predictions, labels) # compare model predictions with target labels\n",
        "      \n",
        "      optimizer.zero_grad() # zero the gradient\n",
        "      loss.backward() # compute gradient\n",
        "      optimizer.step() # take an optimization step\n",
        "      \n",
        "      training_loss += loss.item()*inputs.size(0) # accumulating loss over each batch\n",
        "      _, predicted = predictions.max(1)\n",
        "      correct += (predicted == labels).sum() # accumulating TP + TN\n",
        "\n",
        "    # get average training loss for the epoch across all training examples\n",
        "    # by deviding the accumulated loss by the number of all training examples (20k) \n",
        "    training_loss /= len(train_loader.dataset) # len(train_loader) gives number of batches\n",
        "    # calculate training accuracy for all training examples\n",
        "    train_accuracy = correct / len(train_loader.dataset)\n",
        "\n",
        "    # evaluate current model performance once all batches were proccessed\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for inputs, labels in val_loader:\n",
        "      \n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # Deactivate gradients for making a prediction\n",
        "      with torch.no_grad(): # (faster and less memory usage)\n",
        "        predictions = model(inputs)\n",
        "      loss = loss_fn(predictions, labels)\n",
        "      valid_loss += loss.item()*inputs.size(0)\n",
        "        \n",
        "      _, predicted = predictions.max(1)\n",
        "      correct += (predicted == labels).sum()\n",
        "      \n",
        "    # get average validation loss for the epoch across all validation batches\n",
        "    valid_loss /= len(val_loader.dataset)\n",
        "    val_accuracy = correct / len(val_loader.dataset)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1}, train_loss: {training_loss:.2f},\\\n",
        "          val_loss: {valid_loss:.2f}, val_accuracy = {val_accuracy:.2f},\\\n",
        "          train_accuracy = {train_accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Start training...*"
      ],
      "metadata": {
        "id": "TYLVbpes8lZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(simplenet, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, val_data_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396,
          "referenced_widgets": [
            "61ff8f490b224976bd71aa5259209279",
            "e64d8a876a574324be296a53ef11d7a3",
            "a191296f2ffc46f6bed95363a48e28c1",
            "5a3ed47808b04dec8c0c3d9862cd3361",
            "24545cb3abb2416f9fe6e3b8be059a59",
            "18b24824a2934e6f966937d4c54544a4",
            "f500d9a3e85b47be935c4523347f53ab",
            "5fcd4733ee9a439c90875a814eb351a8",
            "fd8a5604eaaf4d59849e517b3a09755f",
            "28af9eeb43744d668533c5e8a9f79eed",
            "1374dc365dd14a06ac006f3d9c6a0977"
          ]
        },
        "id": "Nfh9AcxQ8WNn",
        "outputId": "f3eb8e09-4e44-4164-e065-f4ec1acc40b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61ff8f490b224976bd71aa5259209279"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, train_loss: 0.99,          val_loss: 0.37, val_accuracy = 0.87,          train_accuracy = 0.67\n",
            "Epoch: 2, train_loss: 0.32,          val_loss: 0.38, val_accuracy = 0.78,          train_accuracy = 0.87\n",
            "Epoch: 3, train_loss: 0.31,          val_loss: 0.31, val_accuracy = 0.88,          train_accuracy = 0.87\n",
            "Epoch: 4, train_loss: 0.22,          val_loss: 0.42, val_accuracy = 0.78,          train_accuracy = 0.92\n",
            "Epoch: 5, train_loss: 0.23,          val_loss: 0.47, val_accuracy = 0.82,          train_accuracy = 0.91\n",
            "Epoch: 6, train_loss: 0.30,          val_loss: 0.35, val_accuracy = 0.88,          train_accuracy = 0.89\n",
            "Epoch: 7, train_loss: 0.17,          val_loss: 0.29, val_accuracy = 0.86,          train_accuracy = 0.94\n",
            "Epoch: 8, train_loss: 0.16,          val_loss: 0.29, val_accuracy = 0.88,          train_accuracy = 0.94\n",
            "Epoch: 9, train_loss: 0.13,          val_loss: 0.28, val_accuracy = 0.89,          train_accuracy = 0.95\n",
            "Epoch: 10, train_loss: 0.09,          val_loss: 0.33, val_accuracy = 0.89,          train_accuracy = 0.97\n",
            "Epoch: 11, train_loss: 0.13,          val_loss: 0.48, val_accuracy = 0.83,          train_accuracy = 0.96\n",
            "Epoch: 12, train_loss: 0.13,          val_loss: 0.28, val_accuracy = 0.88,          train_accuracy = 0.95\n",
            "Epoch: 13, train_loss: 0.12,          val_loss: 0.49, val_accuracy = 0.87,          train_accuracy = 0.95\n",
            "Epoch: 14, train_loss: 0.09,          val_loss: 0.28, val_accuracy = 0.90,          train_accuracy = 0.97\n",
            "Epoch: 15, train_loss: 0.06,          val_loss: 0.29, val_accuracy = 0.89,          train_accuracy = 0.98\n",
            "Epoch: 16, train_loss: 0.09,          val_loss: 0.42, val_accuracy = 0.87,          train_accuracy = 0.96\n",
            "Epoch: 17, train_loss: 0.06,          val_loss: 0.26, val_accuracy = 0.90,          train_accuracy = 0.98\n",
            "Epoch: 18, train_loss: 0.03,          val_loss: 0.28, val_accuracy = 0.91,          train_accuracy = 0.99\n",
            "Epoch: 19, train_loss: 0.03,          val_loss: 0.27, val_accuracy = 0.90,          train_accuracy = 0.99\n",
            "Epoch: 20, train_loss: 0.03,          val_loss: 0.28, val_accuracy = 0.92,          train_accuracy = 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After 20 epochs, we get a validation accuracy of 92 percent and a train accuracy of 99 percent.\n",
        "\n",
        "In a real world scenario, we also would be interested in the final test accuracy to better understand how well our model generalizes to unseen data."
      ],
      "metadata": {
        "id": "1-K8pCF__cx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference and saving model weights"
      ],
      "metadata": {
        "id": "eOe4gSvW9kP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following is just a small example of how we can perform inference (make predictions) with the trained model:"
      ],
      "metadata": {
        "id": "47-GBadbARQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['boot','sandal', 'shoe']\n",
        "\n",
        "img = Image.open(\"./test/boot/boot (948).jpg\")\n",
        "img = transforms(img).to(device)\n",
        "img = torch.unsqueeze(img, 0)\n",
        "\n",
        "# set the model in evaluation mode\n",
        "simplenet.eval()\n",
        "prediction = F.softmax(simplenet(img), dim=1)\n",
        "prediction = prediction.argmax()\n",
        "print(f'{labels[prediction]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV4HZSjx9tY7",
        "outputId": "2acfcf10-8fb6-4173-fbf2-8576273b372d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For a boot image the predicted label is sandal\n",
            "For a sandal image the predicted label is sandal\n",
            "For a shoe image the predicted label is sandal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = simplenet.state_dict()\n",
        "print(state_dict)\n",
        "torch.save(state_dict, \"shoe_model.tar\")"
      ],
      "metadata": {
        "id": "GOmrCrxr07ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test accuracy"
      ],
      "metadata": {
        "id": "HceHMMGJIDDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load(\"shoe_model.tar\")\n",
        "simplenet.load_state_dict(state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXCeuH4yxQVj",
        "outputId": "c22e79b5-e5a5-4166-fded-071dd3074ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, data_loader):\n",
        "    model.eval() # Set model to eval mode\n",
        "    true_preds, num_preds = 0., 0.\n",
        "\n",
        "    with torch.no_grad(): # Deactivate gradients for the following code\n",
        "        for data_inputs, data_labels in data_loader:\n",
        "\n",
        "            # Determine prediction of model on dev set\n",
        "            #data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
        "            preds = model(data_inputs)\n",
        "\n",
        "            _, predicted = preds.max(1)\n",
        "            true_preds += (predicted == data_labels).sum()\n",
        "\n",
        "            # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
        "            num_preds += data_labels.shape[0]\n",
        "\n",
        "    acc = true_preds / num_preds\n",
        "    print(f\"Test accuracy of the model: {100.0*acc:4.2f}%\")"
      ],
      "metadata": {
        "id": "8y8t15rjIByd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(simplenet, test_data_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oei_G2e6JKib",
        "outputId": "2915192a-1a38-4aad-c94e-b3e4768fed54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy of the model: 91.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nPgJWQVq7zb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CaTppULPKze"
      },
      "source": [
        "# PyTorch Lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFZjMmoWzTrh"
      },
      "source": [
        "https://m.youtube.com/watch?v=Hgg8Xy6IRig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXdOBhDvPmXR"
      },
      "source": [
        "PyTorch Lightning is a wrapper library which allows to re-pack the training loop inside a single module. This doesn't really makes you write less code, but you get out a better structured code.\n",
        "\n",
        "For a gentle introduction see https://towardsdatascience.com/from-pytorch-to-pytorch-lightning-a-gentle-introduction-b371b7caaf09\n",
        "\n",
        "Altough, the author suggests to use LightningModule for model and update fuctions, LightningDataModule for DataLoaders, and the Lightning's trainer function to train the model, there are examples where DataLoaders are put inside the LightningModule, which makes it kind of more slick. See an example below in the section on Hugging Face.\n",
        "\n",
        "Lightning also handles logging into TensorBoard, and saving model checkpoints automatically with minimal code overhead from our side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8-gU-yqkD5x"
      },
      "outputs": [],
      "source": [
        "# PyTorch Lightning\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError:\n",
        "    # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
        "    !pip install --quiet pytorch-lightning\n",
        "    import pytorch_lightning as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5we3Su0wkUmz"
      },
      "outputs": [],
      "source": [
        "# Setting the seed\n",
        "pl.seed_everything(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTCJCZjglDvx"
      },
      "source": [
        "In PyTorch Lightning, we define `pl.LightningModule`s (inheriting from `torch.nn.Module`) that organize our code into 5 main sections:\n",
        "\n",
        "- Initialization (__init__), where we create all necessary parameters/models\n",
        "\n",
        "- Optimizers (configure_optimizers) where we create the optimizers, learning rate scheduler, etc.\n",
        "\n",
        "- Training loop (training_step) where we only have to define the loss calculation for a single batch (the loop of optimizer.zero_grad(), loss.backward() and optimizer.step(), as well as any logging/saving operation, is done in the background)\n",
        "\n",
        "- Validation loop (validation_step) where similarly to the training, we only have to define what should happen per step\n",
        "\n",
        "- Test loop (test_step) which is the same as validation, only on a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSEKfEsQljgY"
      },
      "outputs": [],
      "source": [
        "class CIFARModule(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, model_name, model_hparams, optimizer_name, optimizer_hparams):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            model_name - Name of the model/CNN to run. Used for creating the model (see function below)\n",
        "            model_hparams - Hyperparameters for the model, as dictionary.\n",
        "            optimizer_name - Name of the optimizer to use. Currently supported: Adam, SGD\n",
        "            optimizer_hparams - Hyperparameters for the optimizer, as dictionary. This includes learning rate, weight decay, etc.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Exports the hyperparameters to a YAML file, and create \"self.hparams\" namespace\n",
        "        self.save_hyperparameters()\n",
        "        # Create model\n",
        "        self.model = create_model(model_name, model_hparams)\n",
        "        # Create loss module\n",
        "        self.loss_module = nn.CrossEntropyLoss()\n",
        "        # Example input for visualizing the graph in Tensorboard\n",
        "        self.example_input_array = torch.zeros((1, 3, 32, 32), dtype=torch.float32)\n",
        "\n",
        "    def forward(self, imgs):\n",
        "        # Forward function that is run when visualizing the graph\n",
        "        return self.model(imgs)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # We will support Adam or SGD as optimizers.\n",
        "        if self.hparams.optimizer_name == \"Adam\":\n",
        "            # AdamW is Adam with a correct implementation of weight decay (see here for details: https://arxiv.org/pdf/1711.05101.pdf)\n",
        "            optimizer = optim.AdamW(\n",
        "                self.parameters(), **self.hparams.optimizer_hparams)\n",
        "        elif self.hparams.optimizer_name == \"SGD\":\n",
        "            optimizer = optim.SGD(self.parameters(), **self.hparams.optimizer_hparams)\n",
        "        else:\n",
        "            assert False, f\"Unknown optimizer: \\\"{self.hparams.optimizer_name}\\\"\"\n",
        "\n",
        "        # We will reduce the learning rate by 0.1 after 100 and 150 epochs\n",
        "        scheduler = optim.lr_scheduler.MultiStepLR(\n",
        "            optimizer, milestones=[100, 150], gamma=0.1)\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # \"batch\" is the output of the training data loader.\n",
        "        imgs, labels = batch\n",
        "        preds = self.model(imgs)\n",
        "        loss = self.loss_module(preds, labels)\n",
        "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
        "\n",
        "        # Logs the accuracy per epoch to tensorboard (weighted average over batches)\n",
        "        self.log('train_acc', acc, on_step=False, on_epoch=True)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss  # Return tensor to call \".backward\" on\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        preds = self.model(imgs).argmax(dim=-1)\n",
        "        acc = (labels == preds).float().mean()\n",
        "        # By default logs it per epoch (weighted average over batches)\n",
        "        self.log('val_acc', acc)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        preds = self.model(imgs).argmax(dim=-1)\n",
        "        acc = (labels == preds).float().mean()\n",
        "        # By default logs it per epoch (weighted average over batches), and returns it afterwards\n",
        "        self.log('test_acc', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luliO7-pl3LK"
      },
      "source": [
        "Another important part of PyTorch Lightning is the concept of callbacks. Callbacks are self-contained functions that contain the non-essential logic of your Lightning Module. They are usually called after finishing a training epoch, but can also influence other parts of your training loop.\n",
        "\n",
        "For instance, we will use the following two pre-defined callbacks: `LearningRateMonitor` and `ModelCheckpoint`. The learning rate monitor adds the current learning rate to our TensorBoard, which helps to verify that our learning rate scheduler works correctly.\n",
        "\n",
        "The model checkpoint callback allows you to customize the saving routine of your checkpoints. For instance, how many checkpoints to keep, when to save, which metric to look out for, etc. We import them below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCREMi01mD9q"
      },
      "outputs": [],
      "source": [
        "# Callbacks\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd_3BkWpnVfr"
      },
      "source": [
        "To allow running multiple different models with the same Lightning module, we define a function below that maps a model name to the model class. At this stage, the dictionary `model_dict` is empty, but we will fill it throughout the notebook with our new models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rbGU4Wynb5z"
      },
      "outputs": [],
      "source": [
        "model_dict = {}\n",
        "\n",
        "def create_model(model_name, model_hparams):\n",
        "    if model_name in model_dict:\n",
        "        return model_dict[model_name](**model_hparams)\n",
        "    else:\n",
        "        assert False, f\"Unknown model name \\\"{model_name}\\\". Available models are: {str(model_dict.keys())}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh4D91WgniCS"
      },
      "source": [
        "Similarly, to use the activation function as another hyperparameter in our model, we define a “name to function” dict below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PVID_bQnkwJ"
      },
      "outputs": [],
      "source": [
        "act_fn_by_name = {\n",
        "    \"tanh\": nn.Tanh,\n",
        "    \"relu\": nn.ReLU,\n",
        "    \"leakyrelu\": nn.LeakyReLU,\n",
        "    \"gelu\": nn.GELU\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10VPoNNKn3FA"
      },
      "source": [
        "If we pass the classes or objects directly as an argument to the Lightning module, we couldn’t take advantage of PyTorch Lightning’s automatically hyperparameter saving and loading.\n",
        "\n",
        "Besides the `Lightning module`, the second most important module in PyTorch Lightning is the `Trainer`. The trainer is responsible to execute the training steps defined in the Lightning module and completes the framework. Similar to the Lightning module, you can override any key part that you don’t want to be automated, but the default settings are often the best practice to do. The most important functions we use below are:\n",
        "\n",
        "- `trainer.fit`: Takes as input a lightning module, a training dataset, and an (optional) validation dataset. This function trains the given module on the training dataset with occasional validation (default once per epoch, can be changed)\n",
        "\n",
        "- `trainer.test`: Takes as input a model and a dataset on which we want to test. It returns the test metric on the dataset.\n",
        "\n",
        "For training and testing, we don’t have to worry about things like setting the model to eval mode (model.eval()) as this is all done automatically. See below how we define a training function for our models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-Q-FfUwoTwJ"
      },
      "outputs": [],
      "source": [
        "def train_model(model_name, save_name=None, **kwargs):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        model_name - Name of the model you want to run. Is used to look up the class in \"model_dict\"\n",
        "        save_name (optional) - If specified, this name will be used for creating the checkpoint and logging directory.\n",
        "    \"\"\"\n",
        "    if save_name is None:\n",
        "        save_name = model_name\n",
        "\n",
        "    # Create a PyTorch Lightning trainer with the generation callback\n",
        "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, save_name),                          # Where to save models\n",
        "                         gpus=1 if str(device)==\"cuda:0\" else 0,                                             # We run on a single GPU (if possible)\n",
        "                         max_epochs=180,                                                                     # How many epochs to train for if no patience is set\n",
        "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),  # Save the best checkpoint based on the maximum val_acc recorded. Saves only weights and not optimizer\n",
        "                                    LearningRateMonitor(\"epoch\")],                                           # Log learning rate every epoch\n",
        "                         enable_progress_bar=True)                                                           # Set to False if you do not want a progress bar\n",
        "    trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n",
        "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
        "\n",
        "    # Check whether pretrained model exists. If yes, load it and skip training\n",
        "    pretrained_filename = os.path.join(CHECKPOINT_PATH, save_name + \".ckpt\")\n",
        "    if os.path.isfile(pretrained_filename):\n",
        "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
        "        model = CIFARModule.load_from_checkpoint(pretrained_filename) # Automatically loads the model with the saved hyperparameters\n",
        "    else:\n",
        "        pl.seed_everything(42) # To be reproducable\n",
        "        model = CIFARModule(model_name=model_name, **kwargs)\n",
        "        trainer.fit(model, train_loader, val_loader)\n",
        "        model = CIFARModule.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n",
        "\n",
        "    # Test best model on validation and test set\n",
        "    val_result = trainer.test(model, val_loader, verbose=False)\n",
        "    test_result = trainer.test(model, test_loader, verbose=False)\n",
        "    result = {\"test\": test_result[0][\"test_acc\"], \"val\": val_result[0][\"test_acc\"]}\n",
        "\n",
        "    return model, result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NI78k428mml"
      },
      "source": [
        "# Hugging Face with PyTorch Lightning\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM-eclpnSOC3"
      },
      "source": [
        "Hugging Face transformers is a Python library which allows to use pre-trained large language models and fine-tune them on your own data set using its Trainer API (see https://huggingface.co/course/chapter3/1?fw=pt).\n",
        "\n",
        "Following this approach, tuning/training a PyTorch model becomes as easy as using Keras' model.fit(). See the following example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ko2w1CY_-gvn"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch_lightning\n",
        "!pip install tensorboard\n",
        "!pip install nlp\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHSmBOV4-uMi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "import nlp\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HMXSEXd-xp1"
      },
      "outputs": [],
      "source": [
        "class IMDBSentimentClassifier(pl.LightningModule):\n",
        "    \n",
        "    # initilize the model and model loss\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # load a re-trained BERT model from HF transfomers\n",
        "        self.model = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "        # cross-entropy loss from PyTorch\n",
        "        self.loss = torch.nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \n",
        "        # load BERT tokenizer from HF transformers\n",
        "        tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # convert the text field to token ids and add to the data set items\n",
        "        # text sequences also get normalized here\n",
        "        def _tokenize(x):\n",
        "            x['token_ids'] = tokenizer.batch_encode_plus(\n",
        "                    x['text'], \n",
        "                    max_length=32,\n",
        "                    truncation=True, \n",
        "                    padding=True)\n",
        "            return x\n",
        "\n",
        "        # load IMDB data set from HF nlp and split it\n",
        "        def _prepare_ds(split):\n",
        "            ds = nlp.load_dataset('imdb', split='train[:10%]')\n",
        "            ds = ds.map(_tokenize, batched=True)\n",
        "            ds.set_format(type='torch', columns=['token_ids', 'label'])\n",
        "            return ds\n",
        "\n",
        "        self.train_ds, self.test_ds = map(_prepare_ds, ('train', 'test'))\n",
        "\n",
        "    def forward(self, token_ids):\n",
        "        mask = (token_ids != 0).float()\n",
        "        logits, = self.model(token_ids, mask)\n",
        "        return logits\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        logits = self.forward(batch['token_ids'])\n",
        "        loss = self.loss(logits, batch['label']).mean()\n",
        "        return {'loss': loss, 'log': {'train_loss': loss}}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        logits = self.forward(batch['token_ids'])\n",
        "        loss = self.loss(logits, batch['label'])\n",
        "        acc = (logits.argmax(-1) == batch['label']).float()\n",
        "        return {'loss': loss, 'acc': acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        loss = torch.cat([o['loss'] for o in outputs], 0).mean()\n",
        "        acc = torch.cat([o['acc'] for o in outputs], 0).mean()\n",
        "        out = {'val_loss': loss, 'val_acc': acc}\n",
        "        return {**out, 'log': out}\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(\n",
        "                self.train_ds,\n",
        "                batch_size=8,\n",
        "                drop_last=True,\n",
        "                shuffle=True,\n",
        "                )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(\n",
        "                self.test_ds,\n",
        "                batch_size=8,\n",
        "                drop_last=False,\n",
        "                shuffle=True,\n",
        "                )\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.SGD(\n",
        "            self.parameters(),\n",
        "            lr=1e-2,\n",
        "            momentum=0.9,\n",
        "        )\n",
        "    \n",
        "def main(_):\n",
        "    model = IMDBSentimentClassifier()\n",
        "    trainer = pl.Trainer(\n",
        "        default_root_dir='root/logs',\n",
        "        gpus=(1 if torch.cuda.is_available() else 0),\n",
        "        max_epochs=10,\n",
        "        logger=pl.loggers.TensorBoardLogger('root/logs/', name='imdb', version=0),\n",
        "    )\n",
        "    trainer.fit(model)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main(_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKMrIKe9_tA-"
      },
      "source": [
        "However, in case you need any additional customizations for your training you can still utilize all of the underlying PyTorch functionality and implement your own training loop (see https://huggingface.co/course/chapter3/4?fw=pt)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGTnlOo7ssRL"
      },
      "source": [
        "# Fine Tuning Transformer for MultiClass Text Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaC_V4JussRP"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "In this tutorial we will be fine tuning a transformer model for the **Multiclass text classification** problem. \n",
        "This is one of the most common business problems where a given piece of text/sentence/document needs to be classified into one of the categories out of the given list.\n",
        "\n",
        "#### Flow of the notebook\n",
        "\n",
        "The notebook will be divided into seperate sections to provide a organized walk through for the process used. This process can be modified for individual use cases. The sections are:\n",
        "\n",
        "1. [Importing Python Libraries and preparing the environment](#section01)\n",
        "2. [Importing and Pre-Processing the domain data](#section02)\n",
        "3. [Preparing the Dataset and Dataloader](#section03)\n",
        "4. [Creating the Neural Network for Fine Tuning](#section04)\n",
        "5. [Fine Tuning the Model](#section05)\n",
        "6. [Validating the Model Performance](#section06)\n",
        "7. [Saving the model and artifacts for Inference in Future](#section07)\n",
        "\n",
        "#### Technical Details\n",
        "\n",
        "This script leverages on multiple tools designed by other teams. Details of the tools used below. Please ensure that these elements are present in your setup to successfully implement this script.\n",
        "\n",
        " - Data: \n",
        "\t - We are using the News aggregator dataset available at by [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/News+Aggregator)\n",
        "\t - We are referring only to the first csv file from the data dump: `newsCorpora.csv`\n",
        "\t - There are `422937` rows of data.  Where each row has the following data-point: \n",
        "\t\t - ID Numeric ID  \n",
        "\t\t - TITLE News title  \n",
        "\t\t - URL Url  \n",
        "\t\t - PUBLISHER Publisher name  \n",
        "\t\t - CATEGORY News category (b = business, t = science and technology, e = entertainment, m = health)  \n",
        "\t\t - STORY Alphanumeric ID of the cluster that includes news about the same story  \n",
        "\t\t - HOSTNAME Url hostname  \n",
        "\t\t - TIMESTAMP Approximate time the news was published, as the number of milliseconds since the epoch 00:00:00 GMT, January 1, 1970\n",
        "\n",
        "\n",
        " - Language Model Used:\n",
        "\t - DistilBERT this is a smaller transformer model as compared to BERT or Roberta. It is created by process of distillation applied to Bert. \n",
        "\t - [Blog-Post](https://medium.com/huggingface/distilbert-8cf3380435b5)\n",
        "\t - [Research Paper](https://arxiv.org/abs/1910.01108)\n",
        "     - [Documentation for python](https://huggingface.co/transformers/model_doc/distilbert.html)\n",
        "\n",
        "\n",
        " - Hardware Requirements:\n",
        "\t - Python 3.6 and above\n",
        "\t - Pytorch, Transformers and All the stock Python ML Libraries\n",
        "\t - GPU enabled setup \n",
        "\n",
        "\n",
        " - Script Objective:\n",
        "\t - The objective of this script is to fine tune DistilBERT to be able to classify a news headline into the following categories:\n",
        "\t\t - Business\n",
        "\t\t - Technology\n",
        "\t\t - Health\n",
        "\t\t - Entertainment \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmtCFvwEssRQ"
      },
      "source": [
        "<a id='section01'></a>\n",
        "### Importing Python Libraries and preparing the environment\n",
        "\n",
        "At this step we will be importing the libraries and modules needed to run our script. Libraries are:\n",
        "* Pandas\n",
        "* Pytorch\n",
        "* Pytorch Utils for Dataset and Dataloader\n",
        "* Transformers\n",
        "* DistilBERT Model and Tokenizer\n",
        "\n",
        "Followed by that we will preпare the device for CUDA execeution. This configuration is needed if you want to leverage on onboard GPU. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wuMlXT80GAMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f380aeb6-0f3d-4880-c397-8decce026d14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ],
      "source": [
        "# Importing the libraries needed\n",
        "import pandas as pd\n",
        "import torch\n",
        "!pip install transformers\n",
        "import transformers\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import DistilBertModel, DistilBertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xQMKTZ4ARk12"
      },
      "outputs": [],
      "source": [
        "# Setting up the device for GPU usage\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8iS6RCossRS"
      },
      "source": [
        "<a id='section02'></a>\n",
        "### Importing and Pre-Processing the domain data\n",
        "\n",
        "We will be working with the data and preparing for fine tuning purposes. \n",
        "*Assuming that the `newCorpora.csv` is already downloaded in your `data` folder*\n",
        "\n",
        "Import the file in a dataframe and give it the headers as per the documentation.\n",
        "Cleaning the file to remove the unwanted columns and create an additional column for training.\n",
        "The final Dataframe will be something like this:\n",
        "\n",
        "|TITLE|CATEGORY|ENCODED_CAT|\n",
        "|--|--|--|\n",
        "|  title_1|Entertainment | 1 |\n",
        "|  title_2|Entertainment | 1 |\n",
        "|  title_3|Business| 2 |\n",
        "|  title_4|Science| 3 |\n",
        "|  title_5|Science| 3 |\n",
        "|  title_6|Health| 4 |"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEO0q5fCK4hb",
        "outputId": "d5e5e7d0-f7a5-47cd-f1cd-5505a97effde"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/_NN_NLP/PyTorch/datasets/NewsAggregatorDataset.zip ."
      ],
      "metadata": {
        "id": "bKnWbUo4BszQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip NewsAggregatorDataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5m_0ntTLFBF",
        "outputId": "dd6a4a18-8704-4158-e06b-e8094a9a3f05"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  NewsAggregatorDataset.zip\n",
            "  inflating: 2pageSessions.csv       \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._2pageSessions.csv  \n",
            "  inflating: newsCorpora.csv         \n",
            "  inflating: __MACOSX/._newsCorpora.csv  \n",
            "  inflating: readme.txt              \n",
            "  inflating: __MACOSX/._readme.txt   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the csv into pandas dataframe and add the headers\n",
        "df = pd.read_csv('./newsCorpora.csv', sep='\\t', names=['ID','TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME', 'TIMESTAMP'])\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "Vb-MyXkZB64E",
        "outputId": "3f35112b-ffa4-4fa8-c541-ee445fa0e383"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID                                              TITLE  \\\n",
              "0   1  Fed official says weak data caused by weather,...   \n",
              "1   2  Fed's Charles Plosser sees high bar for change...   \n",
              "2   3  US open: Stocks fall after Fed official hints ...   \n",
              "3   4  Fed risks falling 'behind the curve', Charles ...   \n",
              "4   5  Fed's Plosser: Nasty Weather Has Curbed Job Gr...   \n",
              "\n",
              "                                                 URL          PUBLISHER  \\\n",
              "0  http://www.latimes.com/business/money/la-fi-mo...  Los Angeles Times   \n",
              "1  http://www.livemint.com/Politics/H2EvwJSK2VE6O...           Livemint   \n",
              "2  http://www.ifamagazine.com/news/us-open-stocks...       IFA Magazine   \n",
              "3  http://www.ifamagazine.com/news/fed-risks-fall...       IFA Magazine   \n",
              "4  http://www.moneynews.com/Economy/federal-reser...          Moneynews   \n",
              "\n",
              "  CATEGORY                          STORY             HOSTNAME      TIMESTAMP  \n",
              "0        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM      www.latimes.com  1394470370698  \n",
              "1        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM     www.livemint.com  1394470371207  \n",
              "2        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371550  \n",
              "3        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371793  \n",
              "4        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM    www.moneynews.com  1394470372027  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c1d7b18-f722-455c-a30f-9000a2b30773\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>URL</th>\n",
              "      <th>PUBLISHER</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>STORY</th>\n",
              "      <th>HOSTNAME</th>\n",
              "      <th>TIMESTAMP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Fed official says weak data caused by weather,...</td>\n",
              "      <td>http://www.latimes.com/business/money/la-fi-mo...</td>\n",
              "      <td>Los Angeles Times</td>\n",
              "      <td>b</td>\n",
              "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
              "      <td>www.latimes.com</td>\n",
              "      <td>1394470370698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
              "      <td>http://www.livemint.com/Politics/H2EvwJSK2VE6O...</td>\n",
              "      <td>Livemint</td>\n",
              "      <td>b</td>\n",
              "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
              "      <td>www.livemint.com</td>\n",
              "      <td>1394470371207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
              "      <td>http://www.ifamagazine.com/news/us-open-stocks...</td>\n",
              "      <td>IFA Magazine</td>\n",
              "      <td>b</td>\n",
              "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
              "      <td>www.ifamagazine.com</td>\n",
              "      <td>1394470371550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
              "      <td>http://www.ifamagazine.com/news/fed-risks-fall...</td>\n",
              "      <td>IFA Magazine</td>\n",
              "      <td>b</td>\n",
              "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
              "      <td>www.ifamagazine.com</td>\n",
              "      <td>1394470371793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
              "      <td>http://www.moneynews.com/Economy/federal-reser...</td>\n",
              "      <td>Moneynews</td>\n",
              "      <td>b</td>\n",
              "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
              "      <td>www.moneynews.com</td>\n",
              "      <td>1394470372027</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c1d7b18-f722-455c-a30f-9000a2b30773')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c1d7b18-f722-455c-a30f-9000a2b30773 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c1d7b18-f722-455c-a30f-9000a2b30773');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iNCaZ2epNcSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67576ed6-1e46-4a6f-bf77-51e0057e2235"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "# # Removing unwanted columns and only leaving title of news and the category which will be the target\n",
        "df = df[['TITLE','CATEGORY']]\n",
        "# df.head()\n",
        "\n",
        "# # Converting the codes to appropriate categories using a dictionary\n",
        "my_dict = {\n",
        "    'e':'Entertainment',\n",
        "    'b':'Business',\n",
        "    't':'Science',\n",
        "    'm':'Health'\n",
        "}\n",
        "\n",
        "def update_cat(x):\n",
        "    return my_dict[x]\n",
        "\n",
        "df['CATEGORY'] = df['CATEGORY'].apply(lambda x: update_cat(x))\n",
        "\n",
        "encode_dict = {}\n",
        "\n",
        "def encode_cat(x):\n",
        "    if x not in encode_dict.keys():\n",
        "        encode_dict[x]=len(encode_dict)\n",
        "    return encode_dict[x]\n",
        "\n",
        "df['ENCODE_CAT'] = df['CATEGORY'].apply(lambda x: encode_cat(x))\n",
        "df['ENCODE_CAT'].unique().tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLR3UzbJssRT"
      },
      "source": [
        "<a id='section03'></a>\n",
        "### Preparing the Dataset and Dataloader\n",
        "\n",
        "We will start with defining few key variables that will be used later during the training/fine tuning stage.\n",
        "\n",
        "Followed by creation of Dataset class - This defines how the text is pre-processed before sending it to the neural network. We will also define the Dataloader that will feed  the data in batches to the neural network for suitable training and processing. \n",
        "\n",
        "Dataset and Dataloader are constructs of the PyTorch library for defining and controlling the data pre-processing and its passage to neural network. For further reading into Dataset and Dataloader read the [docs at PyTorch](https://pytorch.org/docs/stable/data.html)\n",
        "\n",
        "#### *Triage* Dataset Class\n",
        "- This class is defined to accept the Dataframe as input and generate tokenized output that is used by the DistilBERT model for training. \n",
        "- We are using the DistilBERT tokenizer to tokenize the data in the `TITLE` column of the dataframe. \n",
        "- The tokenizer uses the `encode_plus` method to perform tokenization and generate the necessary outputs, namely: `ids`, `attention_mask`\n",
        "- To read further into the tokenizer, [refer to this document](https://huggingface.co/transformers/model_doc/distilbert.html#distilberttokenizer)\n",
        "- `target` is the encoded category on the news headline. \n",
        "- The *Triage* class is used to create 2 datasets, for training and for validation.\n",
        "- *Training Dataset* is used to fine tune the model: **80% of the original data**\n",
        "- *Validation Dataset* is used to evaluate the performance of the model. The model has not seen this data during training. \n",
        "\n",
        "#### Dataloader\n",
        "- Dataloader is used to for creating training and validation dataloader that load data to the neural network in a defined manner. This is needed because all the data from the dataset cannot be loaded to the memory at once, hence the amount of dataloaded to the memory and then passed to the neural network needs to be controlled.\n",
        "- This control is achieved using the parameters such as `batch_size` and `max_len`.\n",
        "- Training and Validation dataloaders are used in the training and validation part of the flow respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JrBr2YesGdO_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "87bb3d166721429ebff804c155786594",
            "0fa67f15d1d44513a64e123fc5d712de",
            "8d525214bb924788b26b3883e2b6726d",
            "e487980b4b454161babe5b9584d54f87",
            "1482462d6d364e3b863797dba550557c",
            "bc2b177545d64aaba27d8207b822b42c",
            "10d255625fb141da96d7ce8f6676c1ce",
            "98386051f5874b79995aa0e6ea2c3600",
            "ec4a7dd0ba234bd980ed2f5478932774",
            "7b777d491bae430e8ffc1299396d79fe",
            "0532bc6dc1b84e4db093a8d5ccc61ad9",
            "7660c555fd994e00bfa7963c11278876",
            "e2cb9c3047094d349ece72f6d0c6be8e",
            "802f76a3d704475c80444a0ec4de7b40",
            "c51fe7550b364d0082ee67872631fcfb",
            "f182d457f6464f11a8ca352e03e66e63",
            "b2774c6e617c41c89ab8017b8ba967a6",
            "230144b14f774cdcab2844c5014b6aa3",
            "21ae9ef8602e4ef5bdada262ef8751b5",
            "c0fa17090ce842b3aef20d2f839b3702",
            "8820ef4778aa473a9fe173a37daba636",
            "375e40a3091f4b36b7cab8feed453b19",
            "cb2fdb29eaae4f5f9522feef6daaf471",
            "e176ca4cfa694798af5e297bef492f1f",
            "599c4b387dff42d3805ace5b325b0d93",
            "97605971e23f4227b5be3684b11e8892",
            "016c171652c04a308f0ff014eddf6bd8",
            "9cfd65cb5a6345c5945fb57e1e23f6c3",
            "ce5ec1ef6d8c4c10b735e87772b3088d",
            "e92a407c73104127851f87045db23f5e",
            "965b0ffe56e74be385fbfe51c3f50c97",
            "2d410120ee48429b8ba0255a7d9cb0f3",
            "f312b478b72a4e2c900c638c90df8148"
          ]
        },
        "outputId": "14f0cf06-e6c1-4829-d3e2-9e9c34566e38"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87bb3d166721429ebff804c155786594"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7660c555fd994e00bfa7963c11278876"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb2fdb29eaae4f5f9522feef6daaf471"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = 512\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 1e-05\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2vX7kzaAHu39"
      },
      "outputs": [],
      "source": [
        "class Triage(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        title = str(self.data.TITLE[index])\n",
        "        title = \" \".join(title.split())\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            title,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.data.ENCODE_CAT[index], dtype=torch.long)\n",
        "        } \n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Zcwq13c0NE9c",
        "outputId": "3ab01ed8-4467-4081-a6a1-6060bce63fc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (422419, 3)\n",
            "TRAIN Dataset: (337935, 3)\n",
            "TEST Dataset: (84484, 3)\n"
          ]
        }
      ],
      "source": [
        "# Creating the dataset and dataloader for the neural network\n",
        "\n",
        "train_size = 0.8\n",
        "train_dataset=df.sample(frac=train_size,random_state=200)\n",
        "test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = Triage(test_dataset, tokenizer, MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "l1BgA1CkQSYa"
      },
      "outputs": [],
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGwzb4I8ssRV"
      },
      "source": [
        "<a id='section04'></a>\n",
        "### Creating the Neural Network for Fine Tuning\n",
        "\n",
        "#### Neural Network\n",
        " - We will be creating a neural network with the `DistillBERTClass`. \n",
        " - This network will have the DistilBERT Language model followed by a `dropout` and finally a `Linear` layer to obtain the final outputs. \n",
        " - The data will be fed to the DistilBERT Language model as defined in the dataset. \n",
        " - Final layer outputs is what will be compared to the `encoded category` to determine the accuracy of models prediction. \n",
        " - We will initiate an instance of the network called `model`. This instance will be used for training and then to save the final trained model for future inference. \n",
        " \n",
        "#### Loss Function and Optimizer\n",
        " - `Loss Function` and `Optimizer` and defined in the next cell.\n",
        " - The `Loss Function` is used the calculate the difference in the output created by the model and the actual output. \n",
        " - `Optimizer` is used to update the weights of the neural network to improve its performance.\n",
        " \n",
        "#### Further Reading\n",
        "- You can refer to my [Pytorch Tutorials](https://github.com/abhimishra91/pytorch-tutorials) to get an intuition of Loss Function and Optimizer.\n",
        "- [Pytorch Documentation for Loss Function](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
        "- [Pytorch Documentation for Optimizer](https://pytorch.org/docs/stable/optim.html)\n",
        "- Refer to the links provided on the top of the notebook to read more about DistiBERT. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PIHvg8LXssRV"
      },
      "outputs": [],
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
        "\n",
        "class DistillBERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistillBERTClass, self).__init__()\n",
        "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.classifier = torch.nn.Linear(768, 4)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = torch.nn.ReLU()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-y-0nTt4ssRV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743,
          "referenced_widgets": [
            "cef25140a05d494fbe35ea0a0bb8c6fb",
            "5d89c7788c1b4a9d92044930ea761925",
            "1e2d5751a9294464b204fd62ce7f472c",
            "f88fb0663ccb4bc1aac817ccf085ba23",
            "d529c7de41264ca8b9bd3c9786ba53bf",
            "d7694a5d636b4d278dc3896aa3ff46a3",
            "3830cc4647144929a2125bb2ab9f96ff",
            "4f1c4eabf58a42f1884c9941f568a5fa",
            "a0e1b8cdb68d4ac99d95481054242147",
            "8d0bb1f0034646c8adf14e4209ef0d96",
            "ed1cc827de364f6d8ad08ee24088c8c5",
            "76020fe26f4c4801b54a55b5532d079c",
            "52f1ff62c0314111a985cbe60e1f264c",
            "30b27e1123784ecc882ef7bf57869a4c",
            "711f46e07457418aad3887d2b673aece",
            "d5025307af1d4181947d7163868233b9",
            "c4d29d0cfbc94edba147bedd249eefd7",
            "88637af5704941bc858050458f2703b8",
            "9012ce567b214dabbdc6326a0477d847",
            "2bfda572d4ee4d5184c92b43c3582326",
            "4fb126e6a9ca4df38982c070d3d6c49f",
            "39bc8820f666473d91daea177e8a9af1"
          ]
        },
        "outputId": "e60b9041-bbe6-4a2c-8e65-e673519e4895"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cef25140a05d494fbe35ea0a0bb8c6fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76020fe26f4c4801b54a55b5532d079c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistillBERTClass(\n",
              "  (l1): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model = DistillBERTClass()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XyK8dl2mssRV"
      },
      "outputs": [],
      "source": [
        "# Creating the loss function and optimizer\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HTMhVMIssRW"
      },
      "source": [
        "<a id='section05'></a>\n",
        "### Fine Tuning the Model\n",
        "\n",
        "After all the effort of loading and preparing the data and datasets, creating the model and defining its loss and optimizer. This is probably the easier steps in the process. \n",
        "\n",
        "Here we define a training function that trains the model on the training dataset created above, specified number of times (EPOCH), An epoch defines how many times the complete data will be passed through the network. \n",
        "\n",
        "Following events happen in this function to fine tune the neural network:\n",
        "- The dataloader passes data to the model based on the batch size. \n",
        "- Subsequent output from the model and the actual category are compared to calculate the loss. \n",
        "- Loss value is used to optimize the weights of the neurons in the network.\n",
        "- After every 5000 steps the loss value is printed in the console.\n",
        "\n",
        "As you can see just in 1 epoch by the final step the model was working with a miniscule loss of 0.0002485 i.e. the output is extremely close to the actual output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_eQNnwzdssRW"
      },
      "outputs": [],
      "source": [
        "# Function to calcuate the accuracy of the model\n",
        "\n",
        "def calcuate_accu(big_idx, targets):\n",
        "    n_correct = (big_idx==targets).sum().item()\n",
        "    return n_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8bSB-hBmssRW"
      },
      "outputs": [],
      "source": [
        "# Defining the training function on the 80% of the dataset for tuning the distilbert model\n",
        "\n",
        "def train(epoch):\n",
        "    tr_loss = 0\n",
        "    n_correct = 0\n",
        "    nb_tr_steps = 0\n",
        "    nb_tr_examples = 0\n",
        "    model.train()\n",
        "    for _,data in enumerate(training_loader, 0):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(ids, mask)\n",
        "        loss = loss_function(outputs, targets)\n",
        "        #breakpoint()\n",
        "        tr_loss += loss.item()\n",
        "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "        n_correct += calcuate_accu(big_idx, targets)\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples+=targets.size(0)\n",
        "        \n",
        "        if _%5000==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            accu_step = (n_correct*100)/nb_tr_examples \n",
        "            print(f\"Training Loss per 5000 steps: {loss_step}\")\n",
        "            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # # When using GPU\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
        "    epoch_loss = tr_loss/nb_tr_steps\n",
        "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
        "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
        "\n",
        "    return "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNHLi2y_ssRX"
      },
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4PPaos0ssRX"
      },
      "source": [
        "<a id='section06'></a>\n",
        "### Validating the Model\n",
        "\n",
        "During the validation stage we pass the unseen data(Testing Dataset) to the model. This step determines how good the model performs on the unseen data. \n",
        "\n",
        "This unseen data is the 20% of `newscorpora.csv` which was seperated during the Dataset creation stage. \n",
        "During the validation stage the weights of the model are not updated. Only the final output is compared to the actual value. This comparison is then used to calcuate the accuracy of the model. \n",
        "\n",
        "As you can see the model is predicting the correct category of a given headline to a 99.9% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KavRQR27ssRX"
      },
      "outputs": [],
      "source": [
        "def valid(model, testing_loader):\n",
        "    model.eval()\n",
        "    n_correct = 0; n_wrong = 0; total = 0\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.long)\n",
        "            outputs = model(ids, mask).squeeze()\n",
        "            loss = loss_function(outputs, targets)\n",
        "            tr_loss += loss.item()\n",
        "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "            n_correct += calcuate_accu(big_idx, targets)\n",
        "\n",
        "            nb_tr_steps += 1\n",
        "            nb_tr_examples+=targets.size(0)\n",
        "            \n",
        "            if _%5000==0:\n",
        "                loss_step = tr_loss/nb_tr_steps\n",
        "                accu_step = (n_correct*100)/nb_tr_examples\n",
        "                print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
        "                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
        "    epoch_loss = tr_loss/nb_tr_steps\n",
        "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
        "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
        "    \n",
        "    return epoch_accu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJ-lAPhzssRX",
        "outputId": "8bfa6722-0b39-44a9-d94d-310fbc3988ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the validation section to print the accuracy and see how it performs\n",
            "Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch\n",
            "Accuracy on test data = 99.99%\n"
          ]
        }
      ],
      "source": [
        "print('This is the validation section to print the accuracy and see how it performs')\n",
        "print('Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch')\n",
        "\n",
        "acc = valid(model, testing_loader)\n",
        "print(\"Accuracy on test data = %0.2f%%\" % acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpZwg8fMssRX"
      },
      "source": [
        "<a id='section07'></a>\n",
        "### Saving the Trained Model Artifacts for inference\n",
        "\n",
        "This is the final step in the process of fine tuning the model. \n",
        "\n",
        "The model and its vocabulary are saved locally. These files are then used in the future to make inference on new inputs of news headlines.\n",
        "\n",
        "Please remember that a trained neural network is only useful when used in actual inference after its training. \n",
        "\n",
        "In the lifecycle of an ML projects this is only half the job done. We will leave the inference of these models for some other day. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10nOVgYossRX",
        "outputId": "9c211533-8903-4a7e-ba2c-f12414a99c10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All files saved\n",
            "This tutorial is completed\n"
          ]
        }
      ],
      "source": [
        "# Saving the files for re-use\n",
        "\n",
        "output_model_file = './models/pytorch_distilbert_news.bin'\n",
        "output_vocab_file = './models/vocab_distilbert_news.bin'\n",
        "\n",
        "model_to_save = model\n",
        "torch.save(model_to_save, output_model_file)\n",
        "tokenizer.save_vocabulary(output_vocab_file)\n",
        "\n",
        "print('All files saved')\n",
        "print('This tutorial is completed')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face Pipelines for NLP and ASR"
      ],
      "metadata": {
        "id": "6QLnY8h88iYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installation of the transformers library**"
      ],
      "metadata": {
        "id": "8hGvLZ5yXgaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# development version\n",
        "!pip install datasets transformers[sentencepiece]\n",
        "# Datasets is a library for easily accessing and sharing datasets for Audio,\n",
        "# Computer Vision, and Natural Language Processing (NLP) tasks\n",
        "# sentencepiece is a unsupervised tokenizer developed by Google for BERT"
      ],
      "metadata": {
        "id": "hmWhRTaLXSxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9efd3d-1d5e-41f3-a40b-da94aa2628b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.6.1-py3-none-any.whl (441 kB)\n",
            "\u001b[K     |████████████████████████████████| 441 kB 15.7 MB/s \n",
            "\u001b[?25hCollecting transformers[sentencepiece]\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 63.5 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 72.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting dill<0.3.6\n",
            "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[K     |████████████████████████████████| 95 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 74.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 57.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 69.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 75.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 59.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n",
            "Collecting sentencepiece!=0.1.92,>=0.1.91\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 50.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.2 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n",
            "Installing collected packages: urllib3, tokenizers, huggingface-hub, dill, xxhash, transformers, sentencepiece, responses, multiprocess, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "Successfully installed datasets-2.6.1 dill-0.3.5.1 huggingface-hub-0.10.1 multiprocess-0.70.13 responses-0.18.0 sentencepiece-0.1.97 tokenizers-0.13.1 transformers-4.24.0 urllib3-1.25.11 xxhash-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**All magic is behind the pipeline() fuction**\n",
        "\n",
        "The 🤗 Transformers library provides the functionality to create and use shared models.\n",
        "\n",
        "The Model Hub (https://huggingface.co/models) contains thousands of pretrained models that anyone can download and use.\n",
        "\n",
        "The most basic object in the 🤗 Transformers library is the **pipeline() function**. It connects a model with its necessary preprocessing and postprocessing steps, allowing us to directly input any text (*data*) and get an intelligible answer *(model prediction*)."
      ],
      "metadata": {
        "id": "Mj_3i1-xay-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are three main steps involved when you pass some text to a pipeline:\n",
        "\n",
        "1. The text is **preprocessed** into a format the model can understand (tokenization, mapping to vocabulary IDs, truncating/padding of string sequence)\n",
        "2. The preprocessed **inputs are passed to the model** (as embeddings)\n",
        "3. The **predictions of the model are post-processed**, so you can make sense of them (softmax is applied to logits and mapped to text labels)\n",
        "\n",
        "A list of pipelines available in transformers can be found here https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.pipeline.task\n",
        "Without any additional parameters, pipeline() selects a default model defined for a specific task. However, we can adjust it. We can find relevant models for a specific task by visiting the Model Hub (https://huggingface.co/models).\n",
        "\n",
        "When we run pipeline() for the first time, it downloads the required model weights. Then, the weights remain cached in the folder *~/.cache/huggingface/transformers*. You can customize your cache folder by setting the HF_HOME environment variable."
      ],
      "metadata": {
        "id": "NMRiy7xycCLA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All models can also be served via an Inference API (https://huggingface.co/inference-api) which offers 30k words per months in its free version.\n",
        "\n",
        "You can also deploy your own instance on AWS SageMaker (https://aws.amazon.com/blogs/machine-learning/host-hugging-face-transformer-models-using-amazon-sagemaker-serverless-inference/)."
      ],
      "metadata": {
        "id": "JuYUmekpf5NT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
      ],
      "metadata": {
        "id": "rarsN4kHb3dz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "4614460c935c44cea68e1a64eb0ee310",
            "58442c65dafd48c1b858ee6b8f91fc4e",
            "3fe595e2e611410cae1b366d47915013",
            "608c9dd6219f4d14a8c199f9a2ee6570",
            "9a82d69f8e1f44f0b99f586390e498f9",
            "b174fbc747e244988e8c0722c5442876",
            "64a661ae55ee4908a296f3a495fa5fef",
            "2b93c80e182740f5a2d5f5cb3a37e27c",
            "288104ab2dde47d9b7639fd9224cd331",
            "dbd943eff3fd4408b4520dd9414effe1",
            "f71453b79dde45088a3dfa5b3c2b70a4",
            "1aac2625ba9e40cd98e7d6d3267e84bb",
            "c4c67ae2f1f44502a4ce9817ba08763b",
            "3e9fc7782c32473ba0a04e2eda80bb9c",
            "61ed00a4a1914c7cbce1a9a7dfc84982",
            "5d86e2513a8b4ddc8046864d9256cc00",
            "68f87c8657664976885c12f1f89dafe2",
            "a5842e22bce641bca9598e80698b178a",
            "90d9e2c6edc5457f8259aaac2ca47a66",
            "0c785e72ea104fdcae24a5af86451da1",
            "f59ad027f8144dfc834d40a632be2051",
            "71622c008e8f4fa7b2e6fd5085323781",
            "04479378f0614751aa34ab73cd87befd",
            "86f116e137214fe3a987f93e8acb0f14",
            "a8fd72fd86b941fa9356f7222e2931f6",
            "84d9857618464d17919228af6ba3dbe6",
            "d8dc0388cc58499dac0e9b3830ba5a79",
            "e450b509205c4c7094c2dbf74ef9bfc0",
            "49f58b592d694002b53b0475b50add1a",
            "4317295409ea4d11b4b903ee88bc1434",
            "2379f0cda4904509a93b016201cf5729",
            "596021a6115a4d4184055ee7ce937eee",
            "a02587a35d704159b7ae7064779c41aa",
            "e4d56d1edfb64dce9071463cd698dbb7",
            "d33b5b85f135451c85c415d207dba3f1",
            "be0cdd34c671405b8d8d2f61866b929b",
            "6fb79a8253d6413f8670d5f3f8164327",
            "3190f5c5eda044acb9b2108943f2ff22",
            "0b787b2e27184157abbc948e25182d5b",
            "9842c318dc64444a90cd45602c0a717b",
            "9285f2d602df4b5fb687a3d0c7556d73",
            "1118b50162644369adddca26545baf02",
            "ef4d62670c0a4baf8ff3f7e75017b10d",
            "440cc06dd719487a9174cec0cf6eb343"
          ]
        },
        "outputId": "c895d12c-69b0-48bf-ff8e-7166e6c16e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4614460c935c44cea68e1a64eb0ee310"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1aac2625ba9e40cd98e7d6d3267e84bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04479378f0614751aa34ab73cd87befd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4d56d1edfb64dce9071463cd698dbb7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# provide sentences as a list to make inference with several sentences\n",
        "classifier(\n",
        "    [\"I've been waiting for a HuggingFace course my whole life.\",\n",
        "     \"I hate this so much!\"]\n",
        ")"
      ],
      "metadata": {
        "id": "53B_GdpBb8Dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare those two if you're thinking that Transformers provide \"understanding\"\n",
        "classifier([\"I really enjoy to torture others.\",\n",
        "            \"I really enjoy to torture others and make them cry.\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEQ9pX97iIF0",
        "outputId": "2f0f6da3-3f33-49f3-fc6a-0f51a5237bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.5576637387275696},\n",
              " {'label': 'NEGATIVE', 'score': 0.5986902713775635}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For zero-shot classification, for instance, we additionally need to provide a list of candidate labels:"
      ],
      "metadata": {
        "id": "1PrCwHf5_aEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"This is a course about the Transformers library\",\n",
        "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
        ")"
      ],
      "metadata": {
        "id": "2tr4KFaRcJgV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296,
          "referenced_widgets": [
            "8e55859ac5464ed4a3955f649ace83bf",
            "dbb4c1452d334adc96ea972f71098759",
            "b036f433650a4b839f10aaed9abbb085",
            "705f708d21d24803ab63a864bf32e76c",
            "136ddcabca8e4256afb71e04c901b765",
            "4755b9a97219473bbd32d1eda9999e51",
            "fdc19ccdad324ea6b688667c3b646232",
            "39ed4c8f1895440aa0bbad3dbba4fb4b",
            "e644b531b4e945a1bd53e93cb1e27cfc",
            "6a082c467ec441ffb01b374710cedd94",
            "94014b3065a54538bd7144caa6982100",
            "c3b20ca7db9541e9addcf6ba5e906c6d",
            "c247302d7888441eab7d05e8e2f97871",
            "02312060ef764811bf630bce5e89e1d1",
            "6a9edfb5d7aa4507bc30d6b32cda1afc",
            "b21f210db51440699f24a06455f41bde",
            "ad3e795b4a7346a6a456708bd6c2b10f",
            "106b7b0f974f4d2a893546723b06a17f",
            "cd88e47c2c6244d8a41099b9a2d5b42c",
            "b53f63fec94f46c6ab4a3b3f4ffaf023",
            "ec19c52c0fe840139c8ff1f4844ed361",
            "97788bba7f6c42ffa32711ac3ecd46e6",
            "977fa37cfbb1464fba0cd48fd376f0ad",
            "f719b6adc2a84511941c3244b088740d",
            "682660bd9fbb4697bcaf20059e06f40b",
            "369729df6f8d4b0dab34403f9a657f98",
            "3b0be86b988b45318672d72a1c868e54",
            "865fda1651044db4920c3a21cdaf0c84",
            "8578589f9bc74fe88dbbf6ede163c258",
            "556b5c12af1d4c1ba15c783140c4da83",
            "28e6514c05a44097a3cab2397452c48b",
            "0ba33f8a38b445ae9f404e1974752af2",
            "ee2be43ac43f4fbd96c901884f9275a4",
            "55a904a93f2b4b31bb7456e4181a543c",
            "9da5d55f3c14491f90f6cc0939b64b21",
            "aa06e22658ef477fb84e0519c6d7ed51",
            "2d50f019dad044bfafa651204a8bb406",
            "31eff3a113e54ef291b9bf2e01d1b82e",
            "5017132d1b6940d9b2fad1478bd96113",
            "37589ba0426c494eb431411b715f91c2",
            "17955cd0253147c99db6d59b586b2889",
            "bd6b13cede9140008bf929891f83ceca",
            "490c38059e07461987ce6c25357af8d5",
            "19f663c4c21c45a1a5ce38c5d6c4087a",
            "618154be2af44e0bbd55dbd3badb44ed",
            "1bd62314dcab4635aca175e7a3bf9d0f",
            "56dca0b0de7c47ef9ca3ccb523aa9156",
            "1c85c81e5c6640fe8a60b57bff4bda4b",
            "5bc5e4f27f024c4e91b5f80fc3f2756d",
            "ae2abb25b1f4403ba1b4dd480cc93143",
            "9a0e2bdd77cc48ba8aab5f7c037bdf4e",
            "527a69e720684e62885578340eea5b35",
            "6e329f7a87274a62b6de8b6d30435284",
            "4fbd5fd9ddd5419d8a33bd319949587a",
            "6804ad8c46b5478193ddf8df209e2dde",
            "504c685b4b884ff4bfc09aa0b8ccdf8b",
            "248b32f0d96d4362b1bc402396787578",
            "265a5732e968425a8461fdc693a78c3f",
            "b4bb0c5e35984b69bc7391bd2d880393",
            "7f72ef4157364fb1860d856968743d01",
            "1841af1a689949e7866fc5d80fc7798d",
            "2cfaeb3cabc74a28b3a97dd5142e6477",
            "5b964bb2685b490faa0ada107ccf9182",
            "ce9fd1a52d0148b298de82bea27934ec",
            "5635df22dc2c476facfc031edae6605c",
            "6849b047122249ed8141a3045a4dacc6"
          ]
        },
        "outputId": "761e16c1-29a8-4f8b-f1d5-53bbb41bc584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e55859ac5464ed4a3955f649ace83bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3b20ca7db9541e9addcf6ba5e906c6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "977fa37cfbb1464fba0cd48fd376f0ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55a904a93f2b4b31bb7456e4181a543c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "618154be2af44e0bbd55dbd3badb44ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "504c685b4b884ff4bfc09aa0b8ccdf8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'This is a course about the Transformers library',\n",
              " 'labels': ['education', 'business', 'politics'],\n",
              " 'scores': [0.8445988297462463, 0.11197440326213837, 0.04342682659626007]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\n",
        "    \"This is a shit show.\",\n",
        "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-GiwyiilCiG",
        "outputId": "881522c8-b01e-4182-88a0-fff591e432b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'This is a shit show.',\n",
              " 'labels': ['politics', 'business', 'education'],\n",
              " 'scores': [0.5890167951583862, 0.315385639667511, 0.09559757262468338]}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\"In this course, we will teach you how to\")"
      ],
      "metadata": {
        "id": "DbcG8C8vcrmI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284,
          "referenced_widgets": [
            "3abdc2d000fa4186a817ff079e1363bc",
            "b496c1356c0b4e719dd2461e07591260",
            "3c1fc39ecf964f09873f81e1f28f8bc0",
            "625a64a514224bcca3d097a6c96b1f8b",
            "c8752a7bef714a2db4ea479e5d54597b",
            "1d587181d868438aa2abb68fbd58c551",
            "241bd1c1b518478e95c7beb7fc974ac0",
            "7a31785001984075956a90a8ccf17c85",
            "8c2ef4c9b8d84842aad28ded4aa612f1",
            "87a5ec8af2834096a3d8028177ecaabe",
            "cbaf1465c1b94487865d22758679d53c",
            "a6ba16696fdc4485a9021f56da7a95ff",
            "9e84fdf377c64f1e8d93cc6d80169766",
            "5646ca04a72f4f60bf5c93bd746392fb",
            "567dc11deceb493295e451796ef5dc8e",
            "4fea4e9daa8a41c9bebd0f3ea526b87d",
            "01cbd24ae35d4618bbaacfe64348f7cb",
            "21dcb305352149e0a5d33227c0afa3a6",
            "f6125f9f90ca48ba98de4ff50a9fa54b",
            "926a5f3613254fd3b7a1b88af0f1b39b",
            "720e86f38b4b4f0cb9b007a34d65cf27",
            "410b3b6b543844219ccfd99200616672",
            "00ba9f77be5f45368fa637b1a2376324",
            "e5659df342b94ca597e7d16e69d34bb0",
            "08ea4ebdd38f43c6858c596039c9e700",
            "ac3c3d62f48f4e03a2748962a86ba9ba",
            "c6054e581e174bd8b7be52e8d79570fc",
            "71f7626f2ccf421ebfcc75d9e060ef1d",
            "536123e6ba2f4057a4a6ecf87a064714",
            "abd2e6e53bcc4cf0846253697fe29652",
            "388e20ab8fdf4567bb299409eabf0da9",
            "374392602a5a41c386ec9cb16b8e98f7",
            "cf670824cf2a4ac59fb8474562b1a551",
            "242aec6c3b394d3498a95ea7d39cfd01",
            "4bbd35710aac4b08a597a07e0fd7a669",
            "77453b9209e84d528f0c5445c9a95d3a",
            "e133cf4b450144df929c4b736890b601",
            "ddba1b42f9c44d84a8382949223fdf93",
            "2cfc8ab87f4e428dbd03f8503dd96dc2",
            "2c1f492b303a4e809e18f8a136760988",
            "841e290c511947a19fbb5ea2082ebdf5",
            "f21e14be529142649bbdd09ef02bd2e0",
            "8dc1a9a981de41cebd976d12061ba5b5",
            "4299e06c44d7472dbf17e396da2662b4",
            "e2ed68ef58d047dd89dc2c018c358350",
            "0bca5745aff341949bafae6710dc07d0",
            "7e9a4907e80545b291f5e8f29394d066",
            "335b760cdd954f75bf0ca9f00f3d85e4",
            "84f2bce4ba6b4bb881a9c48f5bd8d807",
            "bc9b4adf3fb54c55b4c72978de2e5439",
            "15387850e51e45c48f98346deaf3301a",
            "bcd94bd397ca48eab0979cbd073bcd59",
            "60bfccc88b14456284659a34e0bfa5f3",
            "e6591089896a41688cca1eef4a667e20",
            "484e02a0214e445ca5967e4b63605a5b"
          ]
        },
        "outputId": "49f658a3-d10c-4b1f-841e-5af7509fd6c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/762 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3abdc2d000fa4186a817ff079e1363bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/353M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6ba16696fdc4485a9021f56da7a95ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00ba9f77be5f45368fa637b1a2376324"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "242aec6c3b394d3498a95ea7d39cfd01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2ed68ef58d047dd89dc2c018c358350"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1364: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 50 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'In this course, we will teach you how to get and keep your nose up and go with any of the above tips from our instructors and their teachers. There are some simple tips for teaching your nose up and going with any of the above tips,'}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or do some Named Entity Recognition (NER):"
      ],
      "metadata": {
        "id": "e7mx3duHgQ41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
        "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ],
      "metadata": {
        "id": "Z0_zGBqRgV2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21e0654d-7db2-47b4-9cd7-def3984e8b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.9981694,\n",
              "  'word': 'Sylvain',\n",
              "  'start': 11,\n",
              "  'end': 18},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.9796019,\n",
              "  'word': 'Hugging Face',\n",
              "  'start': 33,\n",
              "  'end': 45},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.9932106,\n",
              "  'word': 'Brooklyn',\n",
              "  'start': 49,\n",
              "  'end': 57}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With transformers we can also do text summarization:"
      ],
      "metadata": {
        "id": "4uRYhEmug9Vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    America has changed dramatically during recent years. Not only has the number of \n",
        "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
        "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
        "    the premier American universities engineering curricula now concentrate on \n",
        "    and encourage largely the study of engineering science. As a result, there \n",
        "    are declining offerings in engineering subjects dealing with infrastructure, \n",
        "    the environment, and related issues, and greater concentration on high \n",
        "    technology subjects, largely supporting increasingly complex scientific \n",
        "    developments. While the latter is important, it should not be at the expense \n",
        "    of more traditional engineering.\n",
        "\n",
        "    Rapidly developing economies such as China and India, as well as other \n",
        "    industrial countries in Europe and Asia, continue to encourage and advance \n",
        "    the teaching of engineering. Both China and India, respectively, graduate \n",
        "    six and eight times as many traditional engineers as does the United States. \n",
        "    Other industrial countries at minimum maintain their output, while America \n",
        "    suffers an increasingly serious decline in the number of engineering graduates \n",
        "    and a lack of well-educated engineers.\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230,
          "referenced_widgets": [
            "db10d9c73e9d46bfaf0e15cbe89e331a",
            "d053885b0f6a421a896f6b56f737a177",
            "a4e1edad10d54b7288655bc8f2a540af",
            "3f202279fd2541d7a0d77ba8fde71591",
            "e21322f1059547fabb994012edabf890",
            "e064f07e630a4b4596af07754270eb6c",
            "c61e4b557ef64054afd1be1c3f7c7f75",
            "7de2ec5e7c714f69b1f1aec7fc559934",
            "a34e159768d14f1d88ef9c1826915d0c",
            "e3410239bf7e428a8e1a220993173428",
            "273cbaeb2dc64749b3a62fb24ca8dc1e",
            "6d03f0d8099749cc904f65b8b275fb8e",
            "340430b1d13d408c9ff513d307c31fb9",
            "167e388b0782441890ca04fbce8f4940",
            "12bb165c38af4498a608ddfd25d66f7d",
            "5cedd683e95d401b84d6948a9b8c1c9c",
            "37824eec39cf42128204bf267092ca10",
            "3ef58a0c21814353b96dd3ab97bd7953",
            "eb8116c0e2b24f3c8bb280e6850f9d79",
            "2c8c58b46e3f418dae1e67d94801973e",
            "27fbc9163982418e85bddbe8cdbbf34a",
            "48e6b622bbd64040ac252b90356e6f16",
            "4162efdc773e45b59b6809448adcdff2",
            "4825fea9fddd4e0f9200257a3b072858",
            "eae81e6418e04f3087404c06f66fde4f",
            "874c36b5005c4619a44f4fb9af7ced45",
            "8ff75f6523fd4f05b8cc09690ab4c589",
            "c0eda12abea04d0e82bfcbc4fc9568fe",
            "07d2e4c0b0274bbeaa16d0ee32567167",
            "aca48d652998485596c33609b87ec2a7",
            "0c2c2ddb5b3c4864bd8a0af06ca4773d",
            "181f77cf27af4bfb9b7ead538a4c1b1b",
            "bbc77be375024173bcdf9d6016ec7a9a",
            "37e11bcbd75442a799ab5764455bf101",
            "1147e97dc2c8417fa31f7637b920a7eb",
            "407c91d3a312443699f25d7d3bc2d1b0",
            "6ed5b8843b614e3792c33dd5a241dfc5",
            "39f5dcdbde824473bb56b4e73f4e7388",
            "ce78c46c688744be8de023583e9d0078",
            "5dff864da9d744508a2ed646a98ca687",
            "c00cb6e47f9c41a5bec0fce9d8d09539",
            "da78f4b725fd43bbbec4ce09b967cc39",
            "09774b48dd444a3494312bf608681697",
            "4d9a036670cc47a3addf1d426fbcc87c",
            "013dbca19c0d4ccfb16eb65f018a2178",
            "3ddaba4b44a3439887737a8b8090e8e8",
            "dffd058c2fbd46b79482239ef744c6dc",
            "d5c4f17390b649d295e2c0fb4dce044d",
            "2504c8fc3dcb4345a506e6b662ee5dd7",
            "d3e63d6b2d6f42058d0dabbecbed5a2e",
            "94f7827b0f1b40e2b72419adbdec43a7",
            "7222c40f469044b59c429d2bb2316082",
            "f68a53e63eab4dd492b092a9dad7e33c",
            "3b26544d17e54290bc3332e0cb8271bc",
            "12b85c8d41ab4cb886c4ffbc3864d08c"
          ]
        },
        "id": "1hQ6LoMVhB5M",
        "outputId": "4099fc02-997b-4ba1-b2b0-d7104ed95934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.76k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db10d9c73e9d46bfaf0e15cbe89e331a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.14G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d03f0d8099749cc904f65b8b275fb8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4162efdc773e45b59b6809448adcdff2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37e11bcbd75442a799ab5764455bf101"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "013dbca19c0d4ccfb16eb65f018a2178"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or translation:"
      ],
      "metadata": {
        "id": "ky0NGaZThaSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "translator(\"Ce cours est produit par Hugging Face.\")"
      ],
      "metadata": {
        "id": "0xh3HEf5hdns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Automatic Speech Recognition:"
      ],
      "metadata": {
        "id": "oo1VAEneCQHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the ASR pipeline\n",
        "asr_pipeline = pipeline(\"automatic-speech-recognition\")\n",
        "\n",
        "# Perform ASR on the downloaded audio file\n",
        "transcription = asr_pipeline('https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac')\n",
        "print('==============================')\n",
        "print(transcription['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li5W7sedCS7j",
        "outputId": "0bfc70eb-b3ff-4ad2-8603-35eb869338de"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/wav2vec2-base-960h and revision 55bb623 (https://huggingface.co/facebook/wav2vec2-base-960h).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "HE HOPED THERE WOULD BE STEW FOR DINNER TURNIPS AND CARROTS AND BRUISED POTATOES AND FAT MUTTON PIECES TO BE LADLED OUT IN THICK PEPPERED FLOWER FAT AND SAUCE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no built-in pipeline for TTS, yet. See https://huggingface.co/tasks/text-to-speech"
      ],
      "metadata": {
        "id": "Pkx5Yi8MHdfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install espnet==202211\n",
        "!pip install simpleaudio"
      ],
      "metadata": {
        "id": "GgquWTvSHi_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall numpy\n",
        "!pip install numpy"
      ],
      "metadata": {
        "id": "ddu2NrocKfe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from espnet2.bin.tts_inference import Text2Speech\n",
        "import simpleaudio as sa"
      ],
      "metadata": {
        "id": "AbKrl2l3KsNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Dear Darth Vader, I hereby submit my application to join the esteemed ranks\\\n",
        "of the Stormtroopers. My unwavering loyalty and precision will serve the Galactic Empire\\\n",
        " with utmost dedication. May the Force be with you. Sincerely, Ivan\"\n",
        "\n",
        "model = Text2Speech.from_pretrained(synthesis_model)\n",
        "speech  = model(text)['wav']\n",
        "audio_array = speech.view(-1).cpu().numpy()\n",
        "play_obj = sa.play_buffer(audio_array, 1, 4, model.fs)\n",
        "play_obj.wait_done()"
      ],
      "metadata": {
        "id": "awQB9EkcIKNU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "87bb3d166721429ebff804c155786594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fa67f15d1d44513a64e123fc5d712de",
              "IPY_MODEL_8d525214bb924788b26b3883e2b6726d",
              "IPY_MODEL_e487980b4b454161babe5b9584d54f87"
            ],
            "layout": "IPY_MODEL_1482462d6d364e3b863797dba550557c"
          }
        },
        "0fa67f15d1d44513a64e123fc5d712de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc2b177545d64aaba27d8207b822b42c",
            "placeholder": "​",
            "style": "IPY_MODEL_10d255625fb141da96d7ce8f6676c1ce",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "8d525214bb924788b26b3883e2b6726d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98386051f5874b79995aa0e6ea2c3600",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec4a7dd0ba234bd980ed2f5478932774",
            "value": 213450
          }
        },
        "e487980b4b454161babe5b9584d54f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b777d491bae430e8ffc1299396d79fe",
            "placeholder": "​",
            "style": "IPY_MODEL_0532bc6dc1b84e4db093a8d5ccc61ad9",
            "value": " 213k/213k [00:00&lt;00:00, 3.48MB/s]"
          }
        },
        "1482462d6d364e3b863797dba550557c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc2b177545d64aaba27d8207b822b42c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10d255625fb141da96d7ce8f6676c1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98386051f5874b79995aa0e6ea2c3600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec4a7dd0ba234bd980ed2f5478932774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b777d491bae430e8ffc1299396d79fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0532bc6dc1b84e4db093a8d5ccc61ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7660c555fd994e00bfa7963c11278876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2cb9c3047094d349ece72f6d0c6be8e",
              "IPY_MODEL_802f76a3d704475c80444a0ec4de7b40",
              "IPY_MODEL_c51fe7550b364d0082ee67872631fcfb"
            ],
            "layout": "IPY_MODEL_f182d457f6464f11a8ca352e03e66e63"
          }
        },
        "e2cb9c3047094d349ece72f6d0c6be8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2774c6e617c41c89ab8017b8ba967a6",
            "placeholder": "​",
            "style": "IPY_MODEL_230144b14f774cdcab2844c5014b6aa3",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "802f76a3d704475c80444a0ec4de7b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21ae9ef8602e4ef5bdada262ef8751b5",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0fa17090ce842b3aef20d2f839b3702",
            "value": 29
          }
        },
        "c51fe7550b364d0082ee67872631fcfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8820ef4778aa473a9fe173a37daba636",
            "placeholder": "​",
            "style": "IPY_MODEL_375e40a3091f4b36b7cab8feed453b19",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.06kB/s]"
          }
        },
        "f182d457f6464f11a8ca352e03e66e63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2774c6e617c41c89ab8017b8ba967a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "230144b14f774cdcab2844c5014b6aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21ae9ef8602e4ef5bdada262ef8751b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0fa17090ce842b3aef20d2f839b3702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8820ef4778aa473a9fe173a37daba636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "375e40a3091f4b36b7cab8feed453b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb2fdb29eaae4f5f9522feef6daaf471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e176ca4cfa694798af5e297bef492f1f",
              "IPY_MODEL_599c4b387dff42d3805ace5b325b0d93",
              "IPY_MODEL_97605971e23f4227b5be3684b11e8892"
            ],
            "layout": "IPY_MODEL_016c171652c04a308f0ff014eddf6bd8"
          }
        },
        "e176ca4cfa694798af5e297bef492f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cfd65cb5a6345c5945fb57e1e23f6c3",
            "placeholder": "​",
            "style": "IPY_MODEL_ce5ec1ef6d8c4c10b735e87772b3088d",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "599c4b387dff42d3805ace5b325b0d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e92a407c73104127851f87045db23f5e",
            "max": 411,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_965b0ffe56e74be385fbfe51c3f50c97",
            "value": 411
          }
        },
        "97605971e23f4227b5be3684b11e8892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d410120ee48429b8ba0255a7d9cb0f3",
            "placeholder": "​",
            "style": "IPY_MODEL_f312b478b72a4e2c900c638c90df8148",
            "value": " 411/411 [00:00&lt;00:00, 16.0kB/s]"
          }
        },
        "016c171652c04a308f0ff014eddf6bd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cfd65cb5a6345c5945fb57e1e23f6c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce5ec1ef6d8c4c10b735e87772b3088d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e92a407c73104127851f87045db23f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "965b0ffe56e74be385fbfe51c3f50c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d410120ee48429b8ba0255a7d9cb0f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f312b478b72a4e2c900c638c90df8148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cef25140a05d494fbe35ea0a0bb8c6fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d89c7788c1b4a9d92044930ea761925",
              "IPY_MODEL_1e2d5751a9294464b204fd62ce7f472c",
              "IPY_MODEL_f88fb0663ccb4bc1aac817ccf085ba23"
            ],
            "layout": "IPY_MODEL_d529c7de41264ca8b9bd3c9786ba53bf"
          }
        },
        "5d89c7788c1b4a9d92044930ea761925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7694a5d636b4d278dc3896aa3ff46a3",
            "placeholder": "​",
            "style": "IPY_MODEL_3830cc4647144929a2125bb2ab9f96ff",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "1e2d5751a9294464b204fd62ce7f472c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f1c4eabf58a42f1884c9941f568a5fa",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0e1b8cdb68d4ac99d95481054242147",
            "value": 483
          }
        },
        "f88fb0663ccb4bc1aac817ccf085ba23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d0bb1f0034646c8adf14e4209ef0d96",
            "placeholder": "​",
            "style": "IPY_MODEL_ed1cc827de364f6d8ad08ee24088c8c5",
            "value": " 483/483 [00:00&lt;00:00, 15.0kB/s]"
          }
        },
        "d529c7de41264ca8b9bd3c9786ba53bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7694a5d636b4d278dc3896aa3ff46a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3830cc4647144929a2125bb2ab9f96ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f1c4eabf58a42f1884c9941f568a5fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0e1b8cdb68d4ac99d95481054242147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d0bb1f0034646c8adf14e4209ef0d96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed1cc827de364f6d8ad08ee24088c8c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76020fe26f4c4801b54a55b5532d079c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52f1ff62c0314111a985cbe60e1f264c",
              "IPY_MODEL_30b27e1123784ecc882ef7bf57869a4c",
              "IPY_MODEL_711f46e07457418aad3887d2b673aece"
            ],
            "layout": "IPY_MODEL_d5025307af1d4181947d7163868233b9"
          }
        },
        "52f1ff62c0314111a985cbe60e1f264c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4d29d0cfbc94edba147bedd249eefd7",
            "placeholder": "​",
            "style": "IPY_MODEL_88637af5704941bc858050458f2703b8",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "30b27e1123784ecc882ef7bf57869a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9012ce567b214dabbdc6326a0477d847",
            "max": 267967963,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2bfda572d4ee4d5184c92b43c3582326",
            "value": 267967963
          }
        },
        "711f46e07457418aad3887d2b673aece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fb126e6a9ca4df38982c070d3d6c49f",
            "placeholder": "​",
            "style": "IPY_MODEL_39bc8820f666473d91daea177e8a9af1",
            "value": " 268M/268M [00:01&lt;00:00, 181MB/s]"
          }
        },
        "d5025307af1d4181947d7163868233b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d29d0cfbc94edba147bedd249eefd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88637af5704941bc858050458f2703b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9012ce567b214dabbdc6326a0477d847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bfda572d4ee4d5184c92b43c3582326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fb126e6a9ca4df38982c070d3d6c49f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39bc8820f666473d91daea177e8a9af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}